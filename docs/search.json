[
  {
    "objectID": "Markov_Switching_Models.html",
    "href": "Markov_Switching_Models.html",
    "title": "Markov-Switching-Models",
    "section": "",
    "text": "In this blogpost I will discuss the underlying theory behind Markov-Switching models, this includes a short review of Markov-Chains, as well as an in-depth derivation of the Hamilton-Filter, the Kim-Algorithm (for smoothed inference) and the EM-Algorithm. The derivations and explanations are mostly taken from my Bachelor Thesis, which discussed these topics as well. The equation numbers are the equation numbers as they are in Bachelor Thesis, so you can find them easily in the original work. My thesis can be downloaded at the end of my “About Me” section and additionally discusses the development of my R package (MSARM) and how MSARM outperforms MSwM regarding estimation robustness.",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#markov-chains",
    "href": "Markov_Switching_Models.html#markov-chains",
    "title": "Markov-Switching-Models",
    "section": "Markov-Chains",
    "text": "Markov-Chains\nWith the general notation out of the way, we can start to build the foundation of Markov-Switching AR models. For that, we start with Markov-Chains in general. Markov-Chains are stochastic processes satisfying the so-called Markov property. More precisely, we consider a sequence of random variables \\(S_t, S_{t-1},...\\) that can take values in the set \\(\\{1, \\dots, N\\}\\), and fulfill the property: \\[\\begin{equation}\n    P(S_t = j \\mid S_{t-1} = i, \\dots, S_1 = a_1) = P(S_t = j \\mid S_{t-1} = i).\n\\end{equation}\\] This means that the next state is conditionally independent of all previous states given the current state. The transition probabilities between the states of such a Markov-Chain are usually summarized in a so-called transition matrix \\(\\Pi\\), where the ith row and jth column element of \\(\\Pi\\) is given by \\((\\Pi){i,j} = \\pi{i,j} = P(S_t = j \\mid S_{t-1} = i)\\). Thereby \\((\\cdot)_{i,j}\\) indicates the ith row and jth column element. Additionally, we want to point out that we will denote the transpose of a matrix \\(A\\) as \\(A'\\) throughout this thesis. Therefore, \\(\\Pi\\) is defined such that the rows indicate the previous state and the columns represent the state being transitioned into. Furthermore, the sum of the row elements must equal 1. It has to be noted that we can represent a Markov-Chain as a Vector-Autoregressive-Process (VAR). The following discussion of representing Markov-Chains as a VAR closely follows Hamilton (1994, page 678-680). Suppose we have an underlying Markov-Chain \\(S_t, S_{t-1},...\\), and the state space is \\(\\{1, \\dots, N\\}\\). We then define: \\[\\begin{equation}\n\\zeta_{t} =\n\\begin{cases}\n(1,0,...,0)', & \\text{if } S_t = 1\\\\\n(0,1,...,0)', & \\text{if } S_t = 2\\\\\n...\\\\\n(0,0,...,1)', & \\text{if } S_t = N\\\\\n\\end{cases}.\n\\end{equation}\\] Thus for \\(S_t = i\\), \\(\\zeta_{t}\\) equals the ith column of \\(I_N\\). If \\(S_t = i\\), then the jth element of \\(\\zeta_{t+1}\\) is a random variable with \\(P((\\zeta_{t+1})_j = 1|S_t = i) = \\pi_{i,j}\\). Thus \\[\\begin{equation}\nE(\\zeta_{t+1}|S_t = i) =\n\\begin{pmatrix}\n\\pi_{i,1}\\\\\n\\pi_{i,2}\\\\\n...\\\\\n\\pi_{i,N}\n\\end{pmatrix}.\n\\end{equation}\\] Furthermore, one should note that \\(E(\\zeta_{t+1}|S_t = i)\\) is the ith column of \\(\\Pi'\\). Knowing for \\(S_t = i\\), \\(\\zeta_{t}\\) is equal to the ith column of \\(I_N\\) it follows that \\(E(\\zeta_{t+1}|\\zeta_{t}) = \\Pi'\\zeta_{t}\\). Due to (1) it holds that \\(E(\\zeta_{t+1}|\\zeta_{t},\\zeta_{t-1},...) = E(\\zeta_{t+1}|\\zeta_{t}) = \\Pi'\\zeta_{t}\\), therefore we can write: \\[\\begin{equation}\n\\zeta_{t+1} = \\Pi'\\zeta_{t} + v_{t+1}; \\quad \\text{where} \\quad v_{t+1} = \\zeta_{t+1} - E(\\zeta_{t+1}|\\zeta_{t},\\zeta_{t-1},...),\n\\end{equation}\\] (4) implicates that: \\[\\begin{equation}\n    \\zeta_{t+m} = (\\Pi')^{m}\\zeta_t + (\\Pi')^{m-1}v_{t+1} + ... + \\Pi'v_{t+m-1} + v_{t+m}.\n\\end{equation}\\] This is due to the following derivation: \\[\\begin{align*}\n\\zeta_{t+m} &= \\Pi'\\zeta_{t+m-1} + v_{t+m}\n\\\\ &= \\Pi'(\\Pi'\\zeta_{t+m-2} + v_{t+m-1}) + v_{t+m}\n\\\\ &= \\Pi'(\\Pi'(\\Pi'\\zeta_{t+m-3} + v_{t+m-2}) + v_{t+m-1}) + v_{t+m}\n\\\\ &= ...\n\\\\ &= (\\Pi')^{m}\\zeta_t + (\\Pi')^{m-1}v_{t+1} + ... + \\Pi'v_{t+m-1} + v_{t+m}.\n\\end{align*}\\]\nAn m-period ahead forecast for a Markov-Chain can therefore be constructed in the following way: \\[\\begin{equation}\n    E(\\zeta_{t+m}|\\zeta_t,\\zeta_{t-1},...) = (\\Pi')^{m}\\zeta_t.\n\\end{equation}\\] This holds because: \\[\\begin{align*}\nE(\\zeta_{t+m}|\\zeta_{t},\\zeta_{t-1},...) &= E(\\Pi'\\zeta_{t+m-1} + v_{t+m}|\\zeta_{t},\\zeta_{t-1},...)\n\\\\ &= E((\\Pi')^{m}\\zeta_t + (\\Pi')^{m-1}v_{t+1} + ... + \\Pi'v_{t+m-1} + v_{t+m}|\\zeta_{t},\\zeta_{t-1},...)\n\\\\ &= (\\Pi')^{m}E(\\zeta_t|\\zeta_{t},\\zeta_{t-1},...) + (\\Pi')^{m-1}E(\\zeta_{t+1} - E(\\zeta_{t+1}|\\zeta_t,\\zeta_{t-1},...)|\\zeta_t,\\zeta_{t-1},...) +\n\\\\ & \\hspace{0.5cm}...\n\\\\ & \\hspace{0.5cm}+ \\Pi'E(\\zeta_{t+m-1} - E(\\zeta_{t+m-1}|\\zeta_{t+m-2},\\zeta_{t-m-3},...)|\\zeta_t,\\zeta_{t-1},...)\n\\\\ & \\hspace{0.5cm}+ E(\\zeta_{t+m} - E(\\zeta_{t+m}|\\zeta_{t+m-1},\\zeta_{t+m-2},...)|\\zeta_t,\\zeta_{t-1},...)\n\\\\ &= (\\Pi')^{m}\\zeta_t + (\\Pi')^{m-1}[E(\\zeta_{t+1}|\\zeta_t,\\zeta_{t-1},...) - E(E(\\zeta_{t+1}|\\zeta_t,\\zeta_{t-1},...)|\\zeta_t,\\zeta_{t-1},...)] +\n\\\\ & \\hspace{0.5cm}...\n\\\\ & \\hspace{0.5cm}+ \\Pi'[E(\\zeta_{t+m-1}|\\zeta_t,\\zeta_{t-1},...) - E(E(\\zeta_{t+m-1}|\\zeta_{t+m-2},\\zeta_{t-m-3},...)|\\zeta_t,\\zeta_{t-1},...)]\n\\\\ & \\hspace{0.5cm}+ E(\\zeta_{t+m}|\\zeta_t,\\zeta_{t-1},...) - E(E(\\zeta_{t+m}|\\zeta_{t+m-1},\\zeta_{t+m-2},...)|\\zeta_t,\\zeta_{t-1},...)\n\\\\ &= (\\Pi')^{m}\\zeta_t.\n\\end{align*}\\] We could now also condition on other random variables, like \\((Y_t, Y_{t-1},...)\\). We summarize these random variables in a vector \\(\\mathcal{Y}_t\\): \\[\\begin{equation}\n    \\mathcal{Y}_t = (Y_t,Y_{t-1},...),\n\\end{equation}\\] the realisation of \\(\\mathcal{Y}_t\\) will be denoted as: \\[\\begin{equation}\n    \\vec{y}_t = (y_t,y_{t-1},...).\n\\end{equation}\\] Furthmore we define: \\[\\begin{equation}\n    \\mathcal{Y}_{t:\\tau} = (Y_t,Y_{t-1},...,Y_{\\tau}),\n\\end{equation}\\] the realisation of \\(\\mathcal{Y}_{t:\\tau}\\) will be denoted as: \\[\\begin{equation}\n    \\vec{y}_{t:\\tau} = (y_t,y_{t-1},...,y_{\\tau}).\n\\end{equation}\\] Generally speaking, \\(\\mathcal{Y}_T\\) will be the total time series of interest and \\(\\vec{y}_T\\) the observed realization. If the process is governed by regime \\(S_t = j\\) at date \\(t\\) then the conditional density of \\(Y_t\\) is assumed to be given by \\(f_{Y_t|S_t,\\mathcal{Y}_{t-1};\\alpha}(y_t|j,\\vec{y}_{t-1})\\). Thereby \\(\\alpha\\) is a vector of parameters characterizing the conditional density function. Furthermore it is assumed that the conditional density depends only on the current regime \\(S_t\\) and not on past regimes, to be more precise it shall hold: \\[\\begin{equation}\n    f_{Y_t|S_t,\\mathcal{Y}_{t-1};\\alpha}(y_t|s_t,\\vec{y}_{t-1}) = f_{Y_t|S_t,S_{t-1},...,\\mathcal{Y}_{t-1};\\alpha}(y_t|s_t,s_{t-1},...,\\vec{y}_{t-1}).\n\\end{equation}\\] Additionally, \\(S_{t+m}\\) shall be conditonally independent of \\(\\mathcal{Y}_t\\) given \\(S_t\\), for \\(m \\geq 1\\), therefore it shall hold that: \\[\\begin{equation}\n    P_{\\theta}(S_{t+m} = j|S_t = i) = P_{\\theta}(S_{t+m} = j|S_t = i, \\mathcal{Y}_t = \\vec{y}_t).\n\\end{equation}\\] One could now condition on this random vector \\(\\mathcal{Y}_t\\), given a parameter vector \\(\\theta\\), which includes the transition probabilities of the Markov-Chain, as well as the parameters of the distribution of \\(Y_t\\), therefore \\(\\theta = (\\Pi,\\alpha)\\). It should be noted that \\(\\Pi\\) has to be understood in this notation, as part of \\(\\theta\\), as the vector of transition probabilities, instead of the matrix of transition probabilities. Still, we believe that this notation improves the readability and understanding of what \\(\\theta\\) is compared to other notations. We can now write: \\[\\begin{equation}\n\\hat{\\zeta}_{t|t} = E_{\\theta}(\\zeta_{t}|\\mathcal{Y}_t = \\vec{y}_t) =\n\\begin{pmatrix}\nP_{\\theta}(S_t = 1|\\mathcal{Y}_t = \\vec{y}_t)\\\\\nP_{\\theta}(S_t = 2|\\mathcal{Y}_t = \\vec{y}_t)\\\\\n...\\\\\nP_{\\theta}(S_t = N|\\mathcal{Y}_t = \\vec{y}_t)\n\\end{pmatrix}.\n\\end{equation}\\] We now want to estimate \\(\\zeta_{t+m}\\) with \\(\\hat{\\zeta}_{t+m|t} = E_{\\theta}(\\zeta_{t+m}|\\mathcal{Y}_t = \\vec{y}_t)\\). From earlier we know that: \\[\\begin{align*}\n\\displaystyle\n(E_{\\theta}(\\zeta_{t+m}|\\mathcal{Y}_t = \\vec{y}_t))_j &= P_{\\theta}(S_{t+m} = j|\\mathcal{Y}_t = \\vec{y}_t)\n\\\\&= \\sum_{i = 1}^{N}P_{\\theta}(S_{t+m} = j,S_t = i|\\mathcal{Y}_t = \\vec{y}_t)\n\\\\&= \\sum_{i = 1}^{N}P_{\\theta}(S_{t+m} = j|S_t = i,\\mathcal{Y}_t = \\vec{y}_t) P_{\\theta}(S_{t} = i|\\mathcal{Y}_t = \\vec{y}_t)\n\\\\ &= \\sum_{i = 1}^{N}P_{\\theta}(S_{t+m} = j|S_t = i)P_{\\theta}(S_t = i|\\mathcal{Y}_t = \\vec{y}_t)\n\\\\ &= ((\\Pi')^m)_{j,}\\hat{\\zeta}_{t|t}.\n\\end{align*}\\] Applying this to all elements we end up with: \\[\\begin{equation}\n    E_{\\theta}(\\zeta_{t+m}|\\mathcal{Y}_t = \\vec{y}_t) = (\\Pi')^m\\hat{\\zeta}_{t|t},\n\\end{equation}\\] compare Hamilton (1994, page 693). This property will be essential later, therefore it is important to keep in mind that this indeed holds true.",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#autoregressive-ar-processes",
    "href": "Markov_Switching_Models.html#autoregressive-ar-processes",
    "title": "Markov-Switching-Models",
    "section": "Autoregressive (AR) Processes",
    "text": "Autoregressive (AR) Processes\nWorking with time series can be tricky, as one always deals with stochastic processes. The idea is the following, if one observes a time series \\(\\vec{y}_T = (y_1,...,y_T)\\), then the observations are the realizations of the random variables \\(\\mathcal{Y}_T = (Y_1,...,Y_T)\\). These random variables, are connected to each other, since they all stem from the same underlying stochastic process. The goal is now to estimate said stochastic process. Before estimating the parameters of a process, it is necessary to decide which process to assume as the underlying (or at least sufficiently similar) process. A rather often utilized process-family are AR processes, an AR(m) has the form: \\[\\begin{align*}\n    Y_t = c + \\phi_1Y_{t-1} + ... + \\phi_mY_{t-m} + U_t; \\quad \\text{where}\\quad U_t \\sim WN(0,\\sigma^2).\n\\end{align*}\\] Thereby \\(WN(0,\\sigma^2)\\) denotes a zero-mean white noise process with variance \\(\\sigma^2\\). The white noise distribution that is most often used is the normal distribution. Therefore \\[\\begin{align*}\n    Y_t = c + \\phi_1Y_{t-1} + ... + \\phi_mY_{t-m} + U_t; \\quad \\text{where}\\quad U_t \\sim N(0,\\sigma^2),\n\\end{align*}\\] would qualify as an AR(m). This framework of an AR(m) with gaussian white noise will be the foundation on which Markov-Switching AR models are built in the next section.\n#Markov-Switching Models (MSM)",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#introduction-to-markov-switching-models",
    "href": "Markov_Switching_Models.html#introduction-to-markov-switching-models",
    "title": "Markov-Switching-Models",
    "section": "Introduction to Markov-Switching Models",
    "text": "Introduction to Markov-Switching Models\nThe basic idea of Markov-Switching models is that the stochastic process \\(Y_1,..., Y_T\\) is itself influenced by another, underlying stochastic process, in this specific case by an underlying Markov-Chain. Therefore, a Markov-Switching AR(1) could take the following form: \\[\\begin{equation}\nY_t = c_{s_t} + \\phi_{s_t}Y_{t-1} + U_{t}; \\quad \\text{where} \\quad U_{t} \\overset{i.i.d.}{\\sim} N(0,\\sigma^2).\n\\end{equation}\\] We could alternatively write: \\[\\begin{align*}\nY_t = X_t'\\beta_{s_t} + U_t \\quad \\text{with} \\quad\nX_t =\n\\begin{pmatrix}\n1\n\\\\Y_{t-1}\n\\end{pmatrix}\n\\quad \\text{and}\n\\quad \\beta_{s_t} =\n\\begin{pmatrix}\nc_{s_t}\n\\\\\\phi_{s_t}\n\\end{pmatrix}.\n\\end{align*}\\] Here \\(S_t\\) follows a first-order Markov-Chain and \\(s_t\\) is the value of the Markov-Chain at time \\(t\\). Furthermore, important assumptions are that (11) and (12) hold true, that there is a maximum lag order (in this case 1) as well as that \\(U_t\\) shall be conditionally independent of \\(S_{t-1},S_{t-2},...\\) given \\(S_t\\) and that \\(S_{t+m}\\) shall be conditionally independent of \\(U_t,U_{t-1},...\\) given \\(S_t\\), for all \\(m \\geq 1\\). To put it more formally, it shall hold that: \\[\\begin{equation}\n    f_{U_t|S_t;\\alpha}(u_t|s_t) = f_{U_t|S_t,S_{t-1},...;\\alpha}(u_t|s_t, s_{t-1},...),\n\\end{equation}\\] \\[\\begin{equation}\n    P_{\\theta}(S_{t+m} = s_{t+m}|S_t =s_t) = P_{\\theta}(S_{t+m} = s_{t+m}|S_t =s_t, U_t = u_t, U_{t-1} = u_{t-1},...).\n\\end{equation}\\] Additionally, a vector of the form of (7) would represent the vector of all observable variables until \\(t\\). It has to be emphasized that the density of \\(Y_t\\) conditioned on \\(S_t = s_t\\) and \\(\\mathcal{Y}_{t-1} = \\vec{y}_{t-1}\\) has the following form: \\[\\begin{equation}\n\\displaystyle\nf_{Y_t|S_t,\\mathcal{Y}_{t-1};\\alpha}(y_t|s_t,\\vec{y}_{t-1}) = \\cfrac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(\\cfrac{-(y_t - c_{s_t} - \\phi_{s_t}y_{t-1})^2}{2\\sigma^2}   \\right).\n\\end{equation}\\] Here we can also see that (11) is indeed true for Markov-Switching AR(m) models with gaussian white noise, as long as earlier states of the Markov-Chain than the current state, \\(s_t\\) don’t influence the parameters that describe the generation of \\(Y_t\\), i.e the intercept, the coefficients and the error-term variance. For this specific AR(1) \\(\\alpha\\) would consist of \\(c_1,...,c_N,\\phi_1,...,\\phi_N\\) and \\(\\sigma^2\\). We summarize the values of the conditional density functions for all potential states of the Markov-Chain in the following vector: \\[\\begin{equation}\n\\eta_t = \\begin{pmatrix}\nf_{Y_t|S_t,\\mathcal{Y}_{t-1}; \\alpha}(y_t|1,\\vec{y}_{t-1})\\\\\n...\\\\\nf_{Y_t|S_t, \\mathcal{Y}_{t-1}; \\alpha}(y_t|N,\\vec{y}_{t-1})\n\\end{pmatrix}.\n\\end{equation}\\]\nNow that this model class has been introduced, we want to further investigate the question of optimal inference regarding the states of the Markov-Chain, often called regimes. In the following sections, the goal is to estimate the parameter vector \\(\\theta = (\\Pi,\\alpha)\\) given \\(\\mathcal{Y}_t = \\vec{y}_{t}\\).",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#optimal-inference-of-the-regimes-and-derivation-of-the-log-likelihood",
    "href": "Markov_Switching_Models.html#optimal-inference-of-the-regimes-and-derivation-of-the-log-likelihood",
    "title": "Markov-Switching-Models",
    "section": "Optimal Inference of the Regimes and Derivation of the Log-Likelihood",
    "text": "Optimal Inference of the Regimes and Derivation of the Log-Likelihood\nBut before we follow this endeavour, we peak into a world where we assume that \\(\\theta\\) is known. Given \\(\\theta\\) we want to get inference regarding the regimes of the time series. We start by summarizing the \\(P_{\\theta}(S_t = j|\\mathcal{Y}_t = \\vec{y}_{t})\\) and \\(P_{\\theta}(S_{t+1} = j|\\mathcal{Y}_t = \\vec{y}_{t})\\) for all \\(j = 1,...,N\\), similarily to (13) in: \\[\\begin{equation}\n\\hat{\\zeta}_{t|t} = \\begin{pmatrix}\nP_{\\theta}(S_t = 1|\\mathcal{Y}_t = \\vec{y}_{t})\\\\\n...\\\\\nP_{\\theta}(S_t = N|\\mathcal{Y}_t = \\vec{y}_{t})\\\\\n\\end{pmatrix}\n\\quad \\text{and} \\quad\n\\hat{\\zeta}_{t+1|t} = \\begin{pmatrix}\nP_{\\theta}(S_{t+1} = 1|\\mathcal{Y}_t = \\vec{y}_{t})\\\\\n...\\\\\nP_{\\theta}(S_{t+1} = N|\\mathcal{Y}_t = \\vec{y}_{t})\\\\\n\\end{pmatrix}.\n\\end{equation}\\] The claim Hamilton makes now is that the optimal inference can be derived by iterating over the following equations: \\[\\begin{equation}\n\\displaystyle\n\\hat{\\zeta}_{t|t} = \\cfrac{(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)}{\\mathbf{1'}(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)},\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\n\\hat{\\zeta}_{t+1|t} = \\Pi'\\hat{\\zeta}_{t|t}.\n\\end{equation}\\] Where \\(\\odot\\) denotes element-by-element multiplication. In addition, the value of the Log-Likelihood function for the vector of all observations \\(\\vec{y}_{T}\\) at the point \\(\\theta\\) is gained as a side product: \\[\\begin{equation}\n\\displaystyle\n\\mathcal{L}(\\theta) = \\sum_{t=1}^{T}\\ln(f_{Y_t|\\mathcal{Y}_{t-1};\\theta}(y_t|\\vec{y}_{t-1})),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\nf_{Y_t|\\mathcal{Y}_{t-1};\\theta}(y_t|\\vec{y}_{t-1}) = \\mathbf{1'}(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t),\n\\end{equation}\\] see Hamilton (1994, page 692). That this is indeed true is shown in the Appendix, section 9.1. Based on this system of two equations and a given \\(\\theta\\) we start with a random \\(\\hat{\\zeta}_{1|0}\\) and iterate over all t until we reach T (T is the number of periods for which observations of the time series exist). This gives us the regime probabilities conditionally on the data until t. Additionally we get the Log-Likelihood function, which can be optimized in \\(\\theta\\) to derive the Maximum Likelihood estimate of \\(\\theta\\). It is important to note that a direct optimization of \\(\\mathcal{L}(\\theta)\\) can be computationally expensive and often leads to suboptimal results. Therefore, Hamilton introduced, in his paper “Analysis of Time Series subject to Changes in Regime” from 1990, an iterative optimization algorithm for \\(\\mathcal{L}(\\theta)\\), which is an application of the EM algorithm. Applying a specific variant of the EM algorithm to this optimization problem, instead of more general optimization algorithms can lead to better and computationally less expensive results, see Hamilton (1990, page 40-41). The details of this specific application of the EM algorithm for the optimization of \\(\\mathcal{L}(\\theta)\\) are shown throughout the following sections, this includes a derivation of an algorithm developed by Kim (1994), which can improve some aspects of the application of the EM algorithm as shown in Hamilton (1990). The derivation shown of the “Kim-Algorithm” is based on Hamilton (1994, page 700-702).",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#smoothed-inference-over-the-regimes",
    "href": "Markov_Switching_Models.html#smoothed-inference-over-the-regimes",
    "title": "Markov-Switching-Models",
    "section": "Smoothed Inference over the Regimes",
    "text": "Smoothed Inference over the Regimes\nBefore further investigating the optimization of the log-likelihood and the associated parameter estimation, we want to first discuss how to get inference on \\(P_{\\theta}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})\\), as this will be essential for the application of the aforementioned EM algorithm. Estimating \\(P_{\\theta}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})\\) is often called “smoothed inference” for the regimes. To get this smoothed inference, we apply the algorithm from Kim (1994). The proposition is that, assuming \\(S_t\\) follows a first order Markov-Chain and that the conditional density, \\(f_{Y_t|S_t,\\mathcal{Y}_{t-1};\\alpha}(y_t|j,\\vec{y}_{t-1})\\), depends only on \\(S_t,S_{t-1},...\\) through \\(S_t\\), i.e. that (11) holds true, an assumption we have already made throughout section 3.1, it shall hold that: \\[\\begin{equation}\n\\displaystyle\n\\hat{\\zeta}_{t|T} = \\hat{\\zeta}_{t|t} \\odot (\\Pi(\\hat{\\zeta}_{t+1|T}(\\div)\\hat{\\zeta}_{t+1|t})),\n\\end{equation}\\] where \\((\\div)\\) is the symbol for element-by-element division, see Hamilton (1994, page 694). To get the values of \\(P_{\\theta}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})\\) for \\(t\\) in \\(1,...,T\\) one starts with \\(t = T-1\\) and iterates backwards. The derivation can be found in the Appendix, section 9.2.",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#optimisation-of-the-conditional-log-likelihood",
    "href": "Markov_Switching_Models.html#optimisation-of-the-conditional-log-likelihood",
    "title": "Markov-Switching-Models",
    "section": "Optimisation of the Conditional Log-Likelihood",
    "text": "Optimisation of the Conditional Log-Likelihood\n\nGeneral EM Algorithm Theory\nWe now turn to the EM algorithm. Assuming we observe \\(\\vec{y}_{T} = (y_1,...,y_T)\\), a trick that is often utilized is to optimize a density function of the form \\(f_{Y_T,...,Y_{m+1}|Y_{m},...,Y_1;\\lambda}(y_T,...,y_{m+1}|y_m,...,y_1)\\) in \\(\\lambda\\) instead of \\(f_{Y_T,...,Y_1;\\theta}(y_T,...,y_1)\\) in \\(\\theta\\). We have to optimize in \\(\\lambda\\) because if we choose such a conditional likelihood function, then we have to make assumptions about how the initial states \\((Y_{m},...,Y_1)\\) are distributed. The simplest approach is to assume that they are seperately drawn from a distribution with the parameters \\(\\rho\\). Thereby \\(\\rho\\) shall be unrelated of \\(\\Pi\\) and \\(\\alpha\\). The new parameter vector \\(\\lambda\\) is therefore defined as \\(\\lambda = (\\Pi,\\alpha,\\rho)\\). The conditional likelihood function is primarily chosen due to practical reasons. Optimizing the likelihood function instead is often more challenging and yields next to no additional gain. Choosing the conditional likelihood enables the application of the EM algorithm, as described by Hamilton (1990), which estimates the parameters with relatively low computational demands, at least compared to other numerical methods, see Hamilton (1990, page 40). Still it has to be emphasized that the EM algorithm that Hamilton introduces only leads to a local maximum of the conditional likelihood function, as will be shown throughout this section. Generally speaking, this is not problematic, as one can start the algorithm with several different values to see whether the results are robust. We start by defining \\[\\begin{equation}\nP_{\\lambda}(S_m = s_m,S_{m-1} = s_{m-1},...,S_1 = s_1|Y_m = y_m,...,Y_1 = y_1) = \\rho_{s_m,...,s_1},\n\\end{equation}\\] and \\[\\begin{equation}\n\\rho = (\\rho_{1,1,..,1},\\rho_{1,1,..,2},...,\\rho_{N,N,..,N}).\n\\end{equation}\\] Thereby (26) is the vector of population probabilities, which are aggregated in (27). With this we can now derive the general EM algorithm: We assume we know nothing about \\(\\lambda\\) and it should be chosen such that the conditional likelihood \\[\\begin{equation}\nf_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_{m};\\lambda}(\\vec{y}_{T:(m+1)}|\\vec{y}_{m}) = f_{Y_T,...,Y_{m+1}|Y_m,...,Y_1;\\lambda}(y_T,...,y_{m+1}|y_m,...,y_1),\n\\end{equation}\\] is maximized, the optimising \\(\\lambda\\) is called \\(\\lambda_{MLE}\\). Furthermore we define \\[\\begin{equation}\n\\displaystyle\n\\mathcal{S} = (S_T,S_{T-1},...,S_1),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\n\\vec{s}_T = (s_T,s_{T-1},...,s_1),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\nZ_t = (S_t,S_{t-1},...,S_{t-m},Y_{t-1},...,Y_{t-m}),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\nz_t = (s_t,s_{t-1},...,s_{t-m},y_{t-1},...,y_{t-m}),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\nf_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m) = f_{Y_T,...,Y_{m+1},S_T,...,S_1|Y_m,...,Y_1;\\lambda}(y_T,...,y_{m+1},s_T,...,s_1|y_m,...,y_1),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\n\\sum_{\\vec{s}_T} P(\\mathcal{S} = \\vec{s}_T) \\, = \\sum_{s_T = 1}^{N}\\cdots\\sum_{s_1 = 1}^{N}P(S_T = s_T,...,S_1 = s_1),\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\nf_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_{m};\\lambda}(\\vec{y}_{T:(m+1)}|\\vec{y}_{m}) = \\sum_{\\vec{s}_T} f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m),\n\\end{equation}\\] and \\[\\begin{equation}\n\\displaystyle\nQ_{\\lambda_l,\\vec{y}_T}(\\lambda_{l+1}) = \\sum_{\\vec{s}_T} \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m).\n\\end{equation}\\] Where we call \\(Q_{\\lambda_l,\\vec{y}_T}(\\lambda_{l+1})\\) the expected log-likelihood. With that remark we finish the necessary notation, which is based on Hamilton (1990, page 42-44) and Hamilton (1990, page 46-47). Now we want to show that the EM algorithm works. It is noteworthy that the EM algorithm can be seen from two different perspectives.\nFirst we want to discuss the EM algorithm as a sequence of optimization problems. \\(\\hat{\\lambda}_l\\) is the result of the lth optimization problem, and we start with a random \\(\\hat{\\lambda}_0\\) for the first optimization problem. We choose \\(\\hat{\\lambda}_{l+1}\\) such that \\(Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda_{l+1})\\) is maximized. We remember: \\[\\begin{align*}\n\\displaystyle\nQ_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda_{l+1}) = \\sum_{\\vec{s}_T} \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)}|\\vec{y}_m).\n\\end{align*}\\] Therefore \\(\\hat{\\lambda}_{l+1}\\) fulfills: \\[\\begin{equation}\n\\displaystyle\n\\sum_{\\vec{s}_T} \\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial\\lambda_{l+1}}\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_{l+1}} \\cdot f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) = 0.\n\\end{equation}\\] It holds that \\(\\hat{\\lambda}_{l+1}\\) is associated with an higher value of the conditional likelihood function than \\(\\hat{\\lambda}_l\\) i.e. \\(f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) \\geq f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)\\). In the following, we closely follow the derivation in Hamilton (1990, page 48-49). Per construction \\(\\hat{\\lambda}_{l+1}\\) maximizes \\(Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda_{l+1})\\), thus: \\[\\begin{align*}\n    Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\hat{\\lambda}_{l+1}) \\geq Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\hat{\\lambda}_{l}) ; \\quad \\text{equal if} \\quad \\hat{\\lambda}_{l+1} = \\hat{\\lambda}_l.\n\\end{align*}\\] We also note that \\(\\forall x \\in \\mathbb{R}^{+}: \\ln(x) \\leq (x-1)\\). This is because we can show that \\(h(x) = x - 1 - \\ln(x)\\) has a minimum at \\(x = 1\\) and \\(h(1)\\) = 0. The first order condition is given by: \\[\\begin{align*}\nh'(x) &= 1 - \\cfrac{1}{x} = 0\n\\\\& \\Leftrightarrow x = 1.\n\\end{align*}\\] That this is indeed a minimum can be shown by checking the second derivative at the point \\(x = 1\\): \\[\\begin{align*}\nh''(1) = \\cfrac{1}{1^2} &gt; 0,\n\\end{align*}\\] thus \\(h(x)\\) has a minimum at the point \\(x = 1\\) and \\(\\forall x \\in \\mathbb{R}^{+}: \\ln(x) \\leq (x-1)\\) is therefore a true statement. We can apply this now and show: \\[\\begin{align*}\n\\displaystyle\n0 &\\leq Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\hat{\\lambda}_{l+1}) - Q_{\\hat{\\lambda}_l, \\vec{y}_T}(\\hat{\\lambda}_l)\n\\\\&= \\sum_{\\vec{s}_T}\\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\& \\hspace{0.5cm} - \\sum_{\\vec{s}_T}\\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_T} \\ln\\left[\\cfrac{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}\\right]f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &\\leq \\sum_{\\vec{s}_T} \\left[\\cfrac{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)} - 1\\right]f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_T} (f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)-f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))\n\\\\ &= f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l+1}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)-f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m).\n\\end{align*}\\] With that we have shown that the algorithm indeed leads to an increase of the conditional likelihood function with each step. Now we want to show that if \\(\\hat{\\lambda}_{l+1} = \\hat{\\lambda}_{l}\\), then the first order condition for maximizing \\(f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_{m};\\lambda}(\\vec{y}_{T:(m+1)}|\\vec{y}_{m})\\) is fulfilled by \\(\\lambda = \\hat{\\lambda}_l\\). This is the case because if: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda_{l+1})}{\\partial \\lambda_{l+1}}\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_l} = 0.\n\\end{align*}\\] Then: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_{m};\\lambda}(\\vec{y}_{T:(m+1)}|\\vec{y}_{m})}{\\partial \\lambda}\\Big|_{\\lambda = \\hat{\\lambda}_l} = 0,\n\\end{align*}\\] this holds true because: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda_{l+1})}{\\partial \\lambda_{l+1}}\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_l}\n&= \\sum_{\\vec{s}_T} \\left(\\cfrac{1}{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)} \\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{\\partial \\lambda_{l+1}}\\right)\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_l}\n\\\\& \\hspace{0.5cm} \\cdot f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_T} \\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{\\partial \\lambda_{l+1}}\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_l}\n\\\\ &= \\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}{\\partial \\lambda_{l+1}}\\Big|_{\\lambda_{l+1} = \\hat{\\lambda}_l}.\n\\end{align*}\\] With that in mind, we proceed to consider the second perspective. One could say that the EM algorithm replaces the unobserved scores with their conditional expectation. Assuming we know \\(\\vec{s}_T\\), then \\(\\hat{\\lambda}_{MLE}(\\vec{s}_T)\\) is characterized by the first-order condition: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\lambda}\\Big|_{\\lambda = \\hat{\\lambda}_{MLE}(\\vec{s}_T)} = 0.\n\\end{align*}\\] Even so we have no data regarding \\(\\mathcal{S}\\) we still have inference regarding \\(\\mathcal{S}\\), at least for the lth step, based on \\(\\hat{\\lambda}_l\\) and \\(\\mathcal{Y}_T = \\vec{y}_T\\). We can formulate: \\[\\begin{equation*}\n\\displaystyle\nP_{\\hat{\\lambda}_l}(\\mathcal{S} = \\vec{s}_T|\\mathcal{Y}_T = \\vec{y}_T) = \\cfrac{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_{m};\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}.\n\\end{equation*}\\] For all possible values of \\(\\mathcal{S}\\), which amounts to \\(N^T\\) possibilities, there exists such a first-order condition. If one weights all these FOCs with the probability \\(P_{\\hat{\\lambda}_l}(\\mathcal{S} = \\vec{s}_T|\\mathcal{Y}_T = \\vec{y}_T)\\) then we choose \\(\\lambda\\) such that: \\[\\begin{align*}\n\\displaystyle\n& \\sum_{\\vec{s}_T} \\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\lambda} \\cdot \\cfrac{f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_{m};\\hat{\\lambda}_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)} = 0\n\\\\ &\\Leftrightarrow \\cfrac{1}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\hat{\\lambda}_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}\\cfrac{\\partial Q_{\\hat{\\lambda}_l,\\vec{y}_T}(\\lambda)}{\\partial \\lambda} = 0\n\\\\ &\\Leftrightarrow \\cfrac{\\partial Q(\\lambda,\\hat{\\lambda}_l,\\vec{y}_T)}{\\partial \\lambda} = 0.\n\\end{align*}\\] This again is the characterizing condition for \\(\\hat{\\lambda}_{l+1}\\) in the first perspective!\n\n\nApplication of the EM Algorithm to Markov-Switching AR Models\nThe next essential step in the theoretical exposition is to demonstrate the application of the EM algorithm to models of the type we are using, that is, models with an underlying Markov-Chain and a dependence on a maximum lag order. Hamilton states that, when using the EM algorithm to maximize the conditional log-likelihood, one obtains three equations to iterate over, see Hamilton (1990, page 51). The equations given by Hamilton are: \\[\\begin{equation}\n\\displaystyle\n\\pi_{i,j}^{(l+1)} = \\cfrac{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j,S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_T)}{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_T)},  \n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\n\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\alpha}\\Big|_{\\alpha = \\alpha_{l+1}} \\cdot P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0,\n\\end{equation}\\] \\[\\begin{equation}\n\\displaystyle\n\\rho_{i_m,...,i_1}^{(l+1)} = P_{\\lambda_l}(S_m = i_m,...,S_1 = i_1|\\mathcal{Y}_T = \\vec{y}_T).  \n\\end{equation}\\]\nWe show that these equations are indeed true in the Appendix, section 9.3. Given this exposition one can apply the EM algorithm to a very broad class of models, even broader than just Markov-Switching AR models, but to actually estimate a specific model, one has to specify the assumed process in more detail. Hamilton (1990) shows only one potential setup for Markov-Switching AR models, we will call this setup “Example 0” throughout this paper. Deriving the results for Example 0 will be the subject of the next section. After this is done we will show 5 more examples, establishing broader AR setups, until the theory for estimating any potential Markov-Switching AR model has been shown. Thereby, Example 1 to Example 3 are specific examples that are introduced to improve the readability of the general cases, Example 4 and Example 5.\n\n\nExample 0: Switching Coefficients and Intercept, Non-Switching \\(\\sigma^2\\)\nHere we assume that the underlying process is given by a Markov-Switching AR(m), which fulfills all assumptions formulated in section 4.1, the only difference is that the assumed underlying AR process now has the following form. \\[\\begin{equation}\n\\displaystyle\nY_t = c_{s_t}+\\phi_{1,s_t}Y_{t-1} +...+ \\phi_{m,s_t}Y_{t-m} + U_t \\quad \\text{where} \\quad  U_{t} \\overset{i.i.d.}{\\sim} N(0,\\sigma^2).\n\\end{equation}\\] We could alternatively write: \\[\\begin{align*}\nY_t = X_t'\\beta_{s_t} + U_t \\quad \\text{with} \\quad\nX_t =\n\\begin{pmatrix}\n1\n\\\\Y_{t-1}\n\\\\...\n\\\\Y_{t-m}\n\\end{pmatrix}\n\\quad \\text{and}\n\\quad \\beta_{s_t} =\n\\begin{pmatrix}\nc_{s_t}\n\\\\\\phi_{1,s_t}\n\\\\...\n\\\\\\phi_{m,s_t}\n\\end{pmatrix}.\n\\end{align*}\\] The following derivation closely follows Hamilton (1990, page 56-58). First, we see that: \\[\\begin{align*}\n\\displaystyle\nf_{Y_t|Z_t;\\alpha}(y_t|z_t) = \\cfrac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(\\cfrac{-(y_t-x_t'\\beta_{s_t})^2}{2\\sigma^2}\\right).\n\\end{align*}\\] It is important to note that \\(x_t\\) denotes the vector of realizations for \\(X_t\\). Then it holds that: \\[\\begin{equation}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j} =\n\\begin{cases}\n    \\cfrac{(y_t - x_t'\\beta_j)x_t}{\\sigma^2}, & \\text{if $S_t = j$}\\\\\n    0, & \\text{otherwise}\n\\end{cases},\n\\end{equation}\\] \\[\\begin{equation}\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\sigma^{-2}} = \\cfrac{\\sigma^2}{2} - \\cfrac{(y_t -x_t'\\beta_{s_t})^2}{2}.\n\\end{equation}\\] (43) is indeed true, because: \\[\\begin{align*}\n\\displaystyle\n\\ln\\left[\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(\\frac{-(y_t-x_t'\\beta_{s_t})^2}{2\\sigma^2}\\right)\\right] &= \\ln\\left(\\frac{1}{\\sqrt{2\\pi}\\sigma}\\right)-\\frac{1}{2}\\left(\\frac{(y_t-x_t'\\beta_{s_t})^2}{\\sigma^2}\\right)\n\\\\ &= \\ln(1) - \\ln(\\sqrt{2\\pi}\\sigma) - \\cfrac{1}{2}(y_t - x_t'\\beta_{s_t})^2\\cfrac{1}{\\sigma^2}\n\\\\ &= -\\ln(\\sqrt{2\\pi}) -\\ln(\\sigma) - \\cfrac{1}{2}(y_t-x_t'\\beta_{s_t})^2\\cfrac{1}{\\sigma^2}\n\\\\ &= -\\ln(\\sqrt{2\\pi}) - \\ln\\left(\\left(\\frac{1}{\\sigma^2}\\right)^{-\\frac{1}{2}}\\right) - \\cfrac{1}{2}(y_t-x_t'\\beta_{s_t})^2\\cfrac{1}{\\sigma^2}.\n\\end{align*}\\] And thus: \\[\\begin{align*}\n\\cfrac{\\partial \\ln\\left[\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(\\frac{-(y_t-x_t'\\beta_{s_t})^2}{2\\sigma^2}\\right)\\right]}{\\partial \\left(\\frac{1}{\\sigma^2}\\right)} &= \\left(\\frac{1}{\\sigma^2}\\right)^{\\frac{1}{2}}\\left(\\frac{1}{2}\\left(\\frac{1}{\\sigma^2}\\right)^{-\\frac{3}{2}}\\right)-\\frac{1}{2}(y_t-x_t'\\beta_{s_t})^2\n\\\\ &= \\cfrac{\\sigma^2}{2} - \\cfrac{(y_t-x_t'\\beta_{s_t})^2}{2}.\n\\end{align*}\\] We insert these results into (39), which leads to: \\[\\begin{equation}\n    \\displaystyle\n    \\sum_{t = m+1}^{T}\\cfrac{(y_t-x_t'\\beta_j^{(l+1)})x_t}{\\sigma_{(l+1)}^2} P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0,\n    \\end{equation}\\] and \\[\\begin{equation}\n    \\displaystyle\n\\sigma_{(l+1)}^2 = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t\\sqrt{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)} - x_t'\\sqrt{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_{s_t}^{(l+1)})^2}{(T-m)}.\n    \\end{equation}\\]\n(44) is true because (42) can be understood as a function of \\(S_t\\), we could write \\[\\begin{align*}\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j} = g_{j}(S_t) =\n\\begin{cases}\n    \\cfrac{(y_t - x_t'\\beta_j)x_t}{\\sigma^2}, & \\text{if $S_t = j$}\\\\\n    0, & \\text{otherwise}\n\\end{cases},\n\\end{align*}\\] thus we can write: \\[\\begin{align*}\n& \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\sum_{s_{t-1} = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_{j}}\\Big|_{\\alpha = \\alpha^{(l+1)}}    P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\ & \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\sum_{s_{t-1} = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N} g_j(s_t)     P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\ & \\Leftrightarrow   \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}g_j(s_t)\\sum_{s_{t-1} = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N} P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\ & \\Leftrightarrow   \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}g_j(s_t) P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\ & \\Leftrightarrow   \\sum_{t = m+1}^{T}\\cfrac{(y_t-x_t'\\beta_{j}^{(l+1)})x_t}{\\sigma_{(l+1)}^2} P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\]\nAnd (45) is true because: \\[\\begin{align*}\n    &\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\left(\\cfrac{\\sigma_{(l+1)}^2}{2}-\\cfrac{(y_t-x_t'\\beta_{s_t}^{(l+1)})^2}{2}\\right)P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n    \\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\left(\\cfrac{\\sigma_{(l+1)}^2}{2} - \\cfrac{(y_t -x_t'\\beta_{s_t}^{(l+1)})^2}{2}\\right)P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n    \\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\\cfrac{\\sigma_{(l+1)}^2}{2} = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N} \\cfrac{(y_t -x_t'\\beta_{s_t}^{(l+1)})^2}{2}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n    \\\\& \\Leftrightarrow (T-m)\\cfrac{\\sigma_{(l+1)}^2}{2} = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t - x_t'\\beta_{s_t}^{(l+1)})^2}{2}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\ &\\Leftrightarrow \\sigma_{(l+1)}^2 = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t - x_t'\\beta_{s_t}^{(l+1)})^2}{(T-m)}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\ &\\Leftrightarrow \\sigma_{(l+1)}^2 = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t\\sqrt{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)} - x_t'\\sqrt{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_{s_t}^{(l+1)})^2}{(T-m)}.\n\\end{align*}\\] Conveniently we can estimate in this specific case all parameters via an OLS Regression. Let us assume we have the parameter vector from the previous iteration \\(\\lambda_l\\) (to start the algorithm one starts with a random \\(\\lambda_0\\)), we first define: \\[\\begin{align*}\n\\displaystyle\ny_t^* = y_t\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} \\quad \\text{and} \\quad x_t^* = x_t\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}.\n\\end{align*}\\] Then we regress \\(y_t^*\\) on \\(x_t^*\\). Thus \\(\\sum_{t = m+1}^{T}(y_t^* - x_t'^*\\beta_j)^2\\) should be minimized, which leads to the following FOC that characterises \\(\\beta_j^{(l+1)}\\): \\[\\begin{align*}\n&\\sum_{t = m+1}^{T}2(y_t^* - (x_t^*)'\\beta_j^{(l+1)})(-1)x_t^* = 0\n\\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}(y_t\\sqrt{P_{\\lambda_l}(S_t = j |\\mathcal{Y}_T = \\vec{y}_T)} - x_t'\\sqrt{P_{\\lambda_l}(S_t = j |\\mathcal{Y}_T = \\vec{y}_T)}\\beta_j^{(l+1)})x_t\\sqrt{P_{\\lambda_l}(S_t = j |\\mathcal{Y}_T = \\vec{y}_T)} = 0\n\\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}(y_t - x_t'\\beta_j^{(l+1)}) x_t P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] Which is equivalent to conditon (44). This is now done \\(N\\) times to estimate \\(\\beta_1^{(l+1)},...,\\beta_N^{(l+1)}\\). By squaring and summing the residuals we get our estimate of \\(\\sigma^2\\): \\[\\begin{align*}\n\\displaystyle\n\\sigma_{(l+1)}^2 = \\cfrac{1}{(T-m)}\\sum_{j = 1}^{N}\\sum_{t = m+1}^{T}(y_t^* - (x_t^*)'\\beta_j^{(l+1)})^2.\n\\end{align*}\\]\nSummarizing one can say, that we achieve our estimate for the \\(\\beta_j\\) of the next iteration by solving the following optimization problem: \\[\\begin{equation}\n\\displaystyle\n    \\arg\\min_{\\beta_j} \\sum_{t = m+1}^{T}(y_t^* - x_t'^*\\beta_j)^2.\n\\end{equation}\\] And then calculate our estimate of the \\(\\sigma^2\\) of the next iteration with: \\[\\begin{equation}\n\\displaystyle\n    \\sigma^2 = \\cfrac{1}{(T-m)}\\sum_{j = 1}^{N}\\sum_{t = m+1}^{T}(y_t^* - (x_t^*)'\\beta_j)^2.\n\\end{equation}\\] Therefore, we have now a specific algorithm for estimating the parameters of a Markov-Switching AR model, where all coefficients switch and the error term variance does not switch. This is the case presented in Hamilton (1990, page 56-58). Sadly Hamilton does not show how to apply the EM algorithm to broader structures of AR models, therefore the following examples are the application of the EM algorithm to broader defined AR processes. To the best of the authors knowledge this presentation of applying the EM algorithm to broader defined specific AR processes is novel.\n\n\nExample 1: Non-Switching Intercept\nFrom the previous derivations, we know that the equations (38), (39), and (40) hold. The five applications of the EM algorithm that we now specifically present are within the class of models for which these three equations were originally derived, i.e. an autoregressive process with a maximum lag order. As opposed to Example 0 we vary the parameters influenced by the underlying Markov-Chain. It is important to emphasize that all models presented are still Markov-Switching AR(m) models with gaussian white noise that fulfill the assumptions made in section 4.1, i.e that fulfill (11), (12), (16) and (17). Assumption (11) is fulfilled because the parameters that describe the generation of \\(Y_t\\) are only directly influenced by the current state of the Markov-Chain \\(s_t\\) and not by earlier states of the Markov-Chain \\(s_{t-1},s_{t-2},...\\), as described in 4.1.\\\\ With that general short discussion out of the way we now turn to Example 1. This time we assume that the coefficients switch, while the intercept and the error term variance do not switch. The assumed process therefore has the following form: \\[\\begin{align*}\n    Y_t = c + \\phi_{1,s_t}Y_{t-1}+...+\\phi_{m,s_t}Y_{t-m} + U_t; \\quad \\text{where} \\quad U_{t} \\overset{i.i.d.}{\\sim} N(0,\\sigma^2).\n\\end{align*}\\] We could alternatively write: \\[\\begin{align*}\nY_t = c + X_t'\\phi_{s_t} + U_t \\quad \\text{with} \\quad\nX_t =\n\\begin{pmatrix}\n    Y_{t-1}\n    \\\\Y_{t-2}\n    \\\\...\n    \\\\Y_{t-m}\n\\end{pmatrix}, \\quad\n\\phi_{s_t} =\n\\begin{pmatrix}\n    \\phi_{1,s_t}\n    \\\\\\phi_{2,s_t}\n    \\\\...\n    \\\\\\phi_{m,s_t}\n\\end{pmatrix} \\quad \\text{and} \\quad\n\\beta_{s_t} =\n\\begin{pmatrix}\n    c\n    \\\\\\phi_{1,s_t}\n    \\\\\\phi_{2,s_t}\n    \\\\...\n    \\\\\\phi_{m,s_t}\n\\end{pmatrix}.\n\\end{align*}\\]\nWe start again with the conditional log-likelihood, which has the following form: \\[\\begin{align*}\n\\displaystyle\n\\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t)) = \\ln(\\cfrac{1}{\\sqrt{2\\pi}\\sigma}) - \\cfrac{(y_t - c - x_t'\\phi_{s_t})^2}{2\\sigma^2}.\n\\end{align*}\\] Now we approach this very similar to how we approached Example 0, we take the derivative in \\(\\alpha\\), only that now there is a switching and a non-switching part in \\(\\beta\\), we have to take the derivative in each. It holds that: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial c} = \\cfrac{(y_t - c -x_t'\\phi_{s_t})}{\\sigma^2} \\quad \\forall s_t \\in \\{1,...,N\\}.\n\\end{align*}\\] We substitute our result in (39): \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{(y_t - c_{(l+1)} -x_t'\\phi_{s_t}^{(l+1)})}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t - c_{(l+1)} -x_t'\\phi_{s_t}^{(l+1)})}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{(l+1)} -x_t'\\phi_{s_t}^{(l+1)})P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - x_t'\\phi_{s_t}^{(l+1)})P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}c_{(l+1)}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - x_t'\\phi_{s_t}^{(l+1)})P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = (T-m)c_{(l+1)}\n\\\\& \\Leftrightarrow c_{(l+1)} = \\cfrac{1}{(T-m)}\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - x_t'\\phi_{s_t}^{(l+1)})P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] The last result: \\[\\begin{equation}\n\\displaystyle\nc_{(l+1)} = \\cfrac{1}{(T-m)}\\sum_{t = m+1}^{T}\\sum_{j = 1}^{N}(y_t - x_t'\\phi_{s_t}^{(l+1)})P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\n\\end{equation}\\] can be understood as a constraint. Next, we take the derivative in \\(\\phi_{j}\\): \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\phi_j} = \\cfrac{(y_t - c - x_t'\\phi_j)x_t}{\\sigma^2}, \\quad \\text{if $S_t = j$, else $0$}.\n\\end{align*}\\] We insert in (39): \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\phi_j}\\Big|_{\\alpha = \\alpha^{(l+1)}}   P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\cfrac{(y_t - c_{(l+1)} - x_t'\\phi_j^{(l+1)})x_t}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}(y_t - c_{(l+1)} - x_t'\\phi_j^{(l+1)})x_tP_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] This is equivalent to the FOC of the following optimization problem: \\[\\begin{equation}\n\\displaystyle\n\\arg\\min_{\\phi_j} \\sum_{t = m+1}^{T}\\left((y_t - c)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - x_t'\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\phi_j\\right)^2.\n\\end{equation}\\] Finally, it remains to differentiate with respect to \\(\\sigma^2\\). In this special case, the differentiation proceeds exactly as in Hamilton’s example, since \\(\\sigma^2\\) still does not switch. Thus, we have: \\[\\begin{align*}\n\\displaystyle\n\\sigma_{(l+1)}^2 = \\cfrac{1}{(T-M)}\\sum_{t = m+1}^T\\sum_{j = 1}^{N}(y_t - c_{(l+1)} - x_t'\\phi_j^{(l+1)})^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] It thus becomes apparent that \\(\\sigma^2\\) does not affect the conditions for \\(c\\) and \\(\\phi_j\\), while these in turn do influence the condition for \\(\\sigma^2\\). Accordingly, as in Hamilton’s example, one can first solve for \\(\\beta_j\\) before determining \\(\\sigma^2\\). However, what changed is that finding \\(\\beta_j\\) is no longer a simple optimization step, since two conditions must now be satisfied simultaneously—namely, those for \\(\\phi_j\\) and \\(c\\). It turns out that simultaneously satisfying both conditions is equivalent to optimizing expression (49) subject to the constraint given by (48). We therefore need to solve the following optimisation problem for \\(\\beta_j\\): \\[\\begin{align*}\n\\displaystyle\n&\\arg\\min_{\\phi_j} \\sum_{t = m+1}^{T}\\left((y_t - c)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - x_t'\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\phi_j\\right)^2 \\quad s.t.\n\\\\&c = \\cfrac{1}{(T-m)}\\sum_{t = m+1}^{T}\\sum_{j = 1}^{N}(y_t - x_t'\\phi_{j})P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] Now we can use this \\(\\beta_j\\), similarly to how we know it from Hamilton and get: \\[\\begin{align*}\n\\displaystyle\n\\sigma^2 = \\cfrac{1}{(T-M)}\\sum_{t = m+1}^T\\sum_{j = 1}^{N}(y_t - c - x_t'\\phi_j)^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] This concludes our \\(\\alpha\\) vector for the next iteration.\n\n\nExample 2: Switching Intercept and Non-Switching Coefficients\nThis time, we reverse the roles; instead of letting the coefficients switch, now only the intercept switches. Therefore, the assumed process would have the following form: \\[\\begin{align*}\n    Y_t = c_{s_t} + \\phi_{1}Y_{t-1}+...+\\phi_{m}Y_{t-m} + U_t; \\quad \\text{where} \\quad U_{t} \\overset{i.i.d.}{\\sim} N(0,\\sigma^2),\n\\end{align*}\\] we could alternatively write: \\[\\begin{align*}\nY_t = c_{s_t} + X_t'\\phi + U_t \\quad \\text{with} \\quad\nX_t =\n\\begin{pmatrix}\n    Y_{t-1}\n    \\\\Y_{t-2}\n    \\\\...\n    \\\\Y_{t-m}\n\\end{pmatrix}, \\quad\n\\phi_{s_t} =\n\\begin{pmatrix}\n    \\phi_{1}\n    \\\\\\phi_{2}\n    \\\\...\n    \\\\\\phi_{m}\n\\end{pmatrix} \\quad \\text{and} \\quad\n\\beta_{s_t} =\n\\begin{pmatrix}\n    c_{s_t}\n    \\\\\\phi_{1}\n    \\\\\\phi_{2}\n    \\\\...\n    \\\\\\phi_{m}\n\\end{pmatrix}.\n\\end{align*}\\]\nIn this case, we differentiate with respect to \\(\\phi\\), \\(c_j\\), and \\(\\sigma^2\\). It is important to note that the error term variance still does not switch. For this setup, we can write: \\[\\begin{align*}\n\\displaystyle\n\\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t)) = \\ln(\\cfrac{1}{\\sqrt{2\\pi}\\sigma}) - \\cfrac{(y_t - c_{s_t} - x_t'\\phi)^2}{2\\sigma^2}.\n\\end{align*}\\] First we differentiate with respect to \\(\\phi\\) and get: \\[\\begin{align*}\n\\displaystyle\n&\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\phi} = \\cfrac{(y_t - c_{s_t} -x_t'\\phi)x_t}{\\sigma^2} \\quad \\forall s_t \\in \\{1,...,N\\}.\n\\end{align*}\\] We insert in (39), this leads us to: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{(y_t - c_{s_t}^{(l+1)} -x_t'\\phi^{(l+1)})x_t}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t - c_{s_t}^{(l+1)} - x_t'\\phi^{(l+1)})x_t}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{s_t}^{(l+1)} - x_t'\\phi^{(l+1)})x_tP_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{s_t}^{(l+1)})x_tP_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) =\n\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}x_t' \\phi^{(l+1)} x_t P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{s_t}^{(l+1)})x_tP_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) =\n\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) x_t x_t' \\phi^{(l+1)}\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{s_t}^{(l+1)})x_tP_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) =\n\\left(\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) x_tx_t'\\right) \\phi^{(l+1)}\n\\\\& \\Leftrightarrow \\phi^{(l+1)} = \\left(\\sum_{t = m+1}^{T}x_tx_t'\\right)^{-1}\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - c_{s_t}^{(l+1)})x_tP_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] Next we differentiate with respect to \\(c_j\\): \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial c_j} = \\cfrac{(y_t - c_{j} -x_t'\\phi)}{\\sigma^2} \\quad \\text{if $S_t = j$, else 0}.\n\\end{align*}\\] Similarily we insert the result in (39): \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial c_j}\\Big|_{\\alpha = \\alpha^{(l+1)}}    P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\cfrac{(y_t - c_j^{(l+1)} - x_t'\\phi^{(l+1)})}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}(y_t - c_j^{(l+1)} - x_t'\\phi^{(l+1)})P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] It should be noted that the last equation is the FOC of the following optimization problem: \\[\\begin{equation}\n\\displaystyle\n\\arg\\min_{c_j} \\sum_{t = m+1}^{T}\\left((y_t - x_t'\\phi)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - c_j\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\right)^2.\n\\end{equation}\\] For \\(\\sigma^2\\), the same condition applies as already formulated by Hamilton, because \\(\\sigma^2\\) again does not switch. Thus, we are in a very similar situation as in the previous example, because the conditions resulting from the derivative with respect to \\(c_j\\), as well as the condition resulting from the derivative with respect to \\(\\phi\\), must be satisfied simultaneously and affect the condition for \\(\\sigma^2\\), whereas \\(\\sigma^2\\) does not affect the former conditions. Therefore, one can first satisfy the first two conditions for all \\(j\\) in order to obtain \\(\\beta_j\\) for all \\(j\\), and then determine \\(\\sigma^2\\) for the next iteration. Furthermore, it follows again that \\(\\beta_j\\), for a given \\(j\\), can be found by solving an optimization problem with an equality constraint. In order to obtain \\(\\beta_j\\), the following optimization problem must be solved: \\[\\begin{align*}\n\\displaystyle\n&\\arg\\min_{c_j} \\sum_{t = m+1}^{T}\\left((y_t - x_t'\\phi)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - c_j\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\right)^2  \\quad s.t.\n\\\\&\\phi = \\left(\\sum_{t = m+1}^{T}x_tx_t'\\right)^{-1}\\sum_{t = m+1}^{T}\\sum_{j = 1}^{N}(y_t - c_j)x_tP_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] As usual we compute: \\[\\begin{align*}\n\\displaystyle\n\\sigma^2 = \\cfrac{1}{(T-M)}\\sum_{t = m+1}^T\\sum_{j = 1}^{N}(y_t - c - x_t'\\phi_j)^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T),\n\\end{align*}\\] and with that we get out \\(\\alpha\\) vector for the next iteration.\n\n\nExample 3: All Parameters Switch\nAs a third example, we now consider the case in which all parameters are allowed to switch. That is, we now allow not only the coefficients and the intercept to switch, but also the variance of the error term. It is important to note that in setups discussed earlier one could have made stronger assumptions, namely it would have been easier to assume in Example 0 to Example 2, that \\(S_t\\) was independent of \\(U_{\\tau}\\) for all \\(t\\) and \\(\\tau\\). Instead we made the weaker assumptions (16) and (17) so that we can now introduce models where the error term variance is allowed to switch, that wouldn’t have been possible with the stronger set of assumptions. That is the reason why all derivations earlier were done with this weaker set of assumptions. That said, we want to point out that we still make the same assumptions as in section 4.1, this is possible due to the weaker set of assumptions, a stronger set of assumptions wouldn’t allow for models like Example 3 and Example 5. Additionally, it should be noted that, in terms of notation, we now again include a \\(1\\) as the first element of \\(X_t\\) to represent the intercept. This leads to the following process formulation: \\[\\begin{align*}\n    y_t = c_{s_t} + \\phi_{1,s_t}Y_{t-1}+...+\\phi_{m,s_t}Y_{t-m} + U_t; \\quad \\text{where} \\quad U_{t} \\overset{}{\\sim} N(0,\\sigma_{s_t}^2),\n\\end{align*}\\] we could alternatively write: \\[\\begin{align*}\nY_t = X_t'\\beta_{s_t} + U_t \\quad \\text{with} \\quad\nX_t =\n\\begin{pmatrix}\n      1\n    \\\\Y_{t-1}\n    \\\\Y_{t-2}\n    \\\\...\n    \\\\Y_{t-m}\n\\end{pmatrix} \\quad \\text{and} \\quad\n\\beta_{s_t} =\n\\begin{pmatrix}\n    c_{s_t}\n    \\\\\\phi_{1,s_t}\n    \\\\\\phi_{2,s_t}\n    \\\\...\n    \\\\\\phi_{m,s_t}\n\\end{pmatrix}.\n\\end{align*}\\]\nAs usual we start with the conditional log-likelihood: \\[\\begin{align*}\n\\displaystyle\n\\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t)) = \\ln(\\cfrac{1}{\\sqrt{2\\pi}\\sigma_{s_t}}) - \\cfrac{(y_t - x_t\\beta_{s_t})^2}{2\\sigma_{s_t}^2}.\n\\end{align*}\\] We now need to take the derivative once with respect to \\(\\beta_j\\) and once with respect to \\(\\sigma_{j}^2\\) for a given \\(j\\). If we first take the derivative with respect to \\(\\beta_j\\), we obtain: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j} = \\cfrac{(y_t - x_t'\\beta_j)x_t}{\\sigma_{j}^2} \\quad \\text{if $S_t = j$, else $0$}.\n\\end{align*}\\] We now substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j}\\Big|_{\\alpha = \\alpha^{(l+1)}}    P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\cfrac{(y_t - x_t'\\beta_j^{(l+1)})x_t}{\\sigma_{j,(l+1)}^2}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] We again observe that this corresponds to the FOC of an optimization problem, namely the following optimization problem: \\[\\begin{align*}\n\\arg\\min_{\\beta_j} \\sum_{t = m+1}^{T}\\left(\\cfrac{y_t}{\\sigma_j}\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - \\cfrac{x_t'}{\\sigma_j}\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_j\\right)^2.\n\\end{align*}\\] Next we take the derivative with respect to \\(\\sigma_{j}^{-2}\\) and get: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\sigma_{j}^{-2}} = \\cfrac{\\sigma_j^{2}}{2} - \\cfrac{(y_t - x_t'\\beta_j)^2}{2} \\quad \\text{if $S_t = j$, else $0$}.\n\\end{align*}\\] We substitute the result into (39), this leads to: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\sigma_{j}^{-2}}\\Big|_{\\alpha = \\alpha^{(l+1)}}    P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\left(\\cfrac{\\sigma_{j,(l+1)}^{2}}{2} - \\cfrac{(y_t - x_t'\\beta_j^{(l+1)})^2}{2}\\right)P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}(\\sigma_{j,(l+1)}^{2} - (y_t - x_t'\\beta_j^{(l+1)})^2)P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sigma_{j,(l+1)}^{2}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}(y_t - x_t'\\beta_j^{(l+1)})^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sigma_{j,(l+1)}^{2}\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}(y_t - x_t'\\beta_j^{(l+1)})^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sigma_{j,(l+1)}^{2} = \\cfrac{\\sum_{t = m+1}^{T}(y_t - x_t'\\beta_j^{(l+1)})^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}.\n\\end{align*}\\] As a result, since \\(\\sigma_j\\) now affects the condition for \\(\\beta_j\\) and vice versa, we once again arrive at a constrained optimization problem, which leads to \\(\\alpha\\) of the next iteration. The constrained optimization problem is given by: \\[\\begin{align*}\n&\\arg\\min_{\\beta_j} \\sum_{t = m+1}^{T}\\left(\\cfrac{y_t}{\\sigma_j}\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - \\cfrac{x_t'}{\\sigma_j}\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_j\\right)^2 \\quad s.t.\n\\\\&\\sigma_j = \\sqrt{\\cfrac{\\sum_{t = m+1}^{T}(y_t - x_t'\\beta_j)^2P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}.\n\\end{align*}\\]\n\n\nExample 4: Arbitrary Subset-Switching of \\((c,\\phi)\\) and Non-Switching \\(\\sigma^2\\)\nThe three previous examples are essentially special cases of the two model formulations that follow. Therefore, the next two examples represent the most general forms of Markov-Switching AR(m) models that will appear in this paper. The model class introduced next assumes that \\(\\sigma^2\\) does not switch, and that an arbitrary subset of \\(\\beta\\) is allowed to switch. Accordingly, we divide the parameter vector \\(\\beta\\) into the switching components, denoted by \\(\\beta^S\\), and the non-switching components, denoted by \\(\\beta^F\\). The underlying process is therefore formulated as follows: \\[\\begin{align*}\n    Y_t = (X_t^F)'\\beta^F + (X_t^S)'\\beta_{s_t}^S +U_t; \\quad \\text{where} \\quad U_{t} \\overset{i.i.d.}{\\sim} N(0,\\sigma^2) \\quad \\text{and} \\quad X_t =\n\\begin{pmatrix}\n      1\n    \\\\Y_{t-1}\n    \\\\Y_{t-2}\n    \\\\...\n    \\\\Y_{t-m}\n\\end{pmatrix}.\n\\end{align*}\\] Thereby \\(X_t^F\\) and \\(X_t^S\\) are defined such that their elements do not overlap and that the elements of both vectors together are the elements of \\(X_t\\), to put it more formally: Let \\(I^F, I^S \\subset \\{1, \\dots, m+1\\}\\) be disjoint index sets such that \\(I^F \\cap I^S = \\emptyset\\) and \\(I^F \\cup I^S = \\{1, \\dots, m+1\\}\\), where \\(m+1\\) is the number of coefficients plus intercept. Then we define [ X_t^F = ((X_{t})i){i I^F}, X_t^S = ((X_{t})i){i I^S}. ] Again we start with the conditional log-likelihood: \\[\\begin{align*}\n\\displaystyle\n\\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t)) = \\ln(\\cfrac{1}{\\sqrt{2\\pi}\\sigma}) - \\cfrac{(y_t - (x_t^S)'\\beta_{s_t}^S - (x_t^F)'\\beta^F)^2}{2\\sigma^2}.\n\\end{align*}\\] Accordingly, for this model class, we need to take the derivative with respect to \\(\\sigma^2\\), \\(\\beta_j^S\\), and \\(\\beta^F\\). We will start with \\(\\beta_j^S\\): \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j^S} = \\cfrac{(y_t - (x_t^S)'\\beta_j^S - (x_t^F)'\\beta^F)x_{t}^{S}}{\\sigma^2} \\quad \\text{if $S_t = j$, else $0$}.\n\\end{align*}\\] We can now substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j^S}\\Big|_{\\alpha = \\alpha^{(l+1)}}    P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}(y_t - (x_t^S)'\\beta_{j,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^S P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] This, in turn, corresponds to the FOC of the following optimization problem: \\[\\begin{align*}\n\\arg\\min_{\\beta_j^S} \\sum_{t = m+1}^{T}\\left((y_t - (x_t^F)'\\beta^F)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - (x_t^S)'\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_j^S\\right)^2.\n\\end{align*}\\] Next, if we take the derivative with respect to \\(\\beta^F\\), we obtain: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta^F} = \\cfrac{(y_t - (x_t^S)'\\beta_j^S - (x_t^F)'\\beta^F)x_t^F}{\\sigma^2} \\quad \\forall s_t \\in \\{1,...,N\\}.\n\\end{align*}\\] We substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^F}{\\sigma_{(l+1)}^2}P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(x_t^F)'\\beta_{(l+1)}^Fx_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}(x_t^F)'\\beta_{(l+1)}^Fx_t^F\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\beta_{(l+1)}^F\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F P_{\\lambda_l}(s_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\right)\\beta_{(l+1)}^F\n\\\\& \\Leftrightarrow \\beta_{(l+1)}^F = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\right)^{-1}\\left(\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)\\right).\n\\end{align*}\\] For this generalized model class, where arbitrary parameters can switch except for the error term variance, which can not switch, we thus obtain the following constrained optimization problem to determine \\(\\beta^F\\) and \\(\\beta_j^S\\) for all \\(j\\). \\[\\begin{align*}\n&\\arg\\min_{\\beta_j^S} \\sum_{t = m+1}^{T}\\left((y_t - (x_t^F)'\\beta^F)\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)} - (x_t^S)'\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}\\beta_j^S\\right)^2 \\quad s.t.\n\\\\& \\beta^F = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\right)^{-1}\\left(\\sum_{t = m+1}^{T}\\sum_{j = 1}^{N}(y_t - (x_t^S)'\\beta_j^S)x_t^F P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\\right).\n\\end{align*}\\] We then calculate, as usual: \\[\\begin{align*}\n\\displaystyle\n\\sigma^2 = \\cfrac{1}{(T-M)}\\sum_{t = m+1}^T\\sum_{j = 1}^{N}(y_t - x_t'\\beta_j)^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T).\n\\end{align*}\\] and thus obtain our new \\(\\alpha\\) vector for the next iteration.\n\n\nExample 5: Arbitrary Subset-Switching of \\((c,\\phi)\\) and Switching \\(\\sigma^2\\)\nWith Example 5, we complete the generalization of the application of the EM algorithm to underlying AR(m) models, as Example 4 and Example 5 together allow for selecting any arbitrary subset of parameters in an AR(m) context for switching. In this final example, we assume the following underlying process: \\[\\begin{align*}\n    Y_t = (X_t^F)'\\beta^F + (X_t^S)'\\beta_{s_t}^S +U_t; \\quad \\text{where} \\quad U_{t} \\overset{}{\\sim} N(0,\\sigma_{s_t}^2) \\quad \\text{and} \\quad X_t =\n\\begin{pmatrix}\n      1\n    \\\\Y_{t-1}\n    \\\\Y_{t-2}\n    \\\\...\n    \\\\Y_{t-m}\n\\end{pmatrix}.\n\\end{align*}\\] Thereby, \\(X_t^F\\) and \\(X_t^S\\) are defined such that their elements do not overlap and that the elements of both vectors together are the elements of \\(X_t\\), to put it more formally: Let \\(I^F, I^S \\subset \\{1, \\dots, m+1\\}\\) be disjoint index sets such that \\(I^F \\cap I^S = \\emptyset\\) and \\(I^F \\cup I^S = \\{1, \\dots, m+1\\}\\), where \\(m+1\\) is the number of coefficients plus intercept. Then we define [ X_t^F = ((X_{t})i){i I^F}, X_t^S = ((X_{t})i){i I^S}. ] Again, we start with the conditional log-liklihood, which would be in this case: \\[\\begin{align*}\n\\displaystyle\n\\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t)) = \\ln\\left(\\cfrac{1}{\\sqrt{2\\pi}\\sigma_{s_t}}\\right) - \\cfrac{(y_t - (x_t^S)'\\beta_{s_t}^S - (x_t^F)'\\beta^F)^2}{2\\sigma_{s_t}^2}.\n\\end{align*}\\] Accordingly, we need to take the derivative with respect to \\(\\sigma_j^2\\), \\(\\beta_j^S\\), and \\(\\beta^F\\). We begin with the derivative with respect to \\(\\beta_j^S\\). \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j^S} = \\cfrac{(y_t - (x_t^S)'\\beta_j^S - (x_t^F)'\\beta^F)x_{t}^{S}}{\\sigma_j^2} \\quad \\text{if $S_t = j$, else $0$}.\n\\end{align*}\\] We now substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta_j^S}\\Big|_{\\alpha = \\alpha^{(l+1)}}     P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\cfrac{(y_t - (x_t^S)'\\beta_{j,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^S}{\\sigma_{j,(l+1)}^2}P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0.\n\\end{align*}\\] This, in turn, corresponds to the FOC of the following optimization problem: \\[\\begin{align*}\n\\arg\\min_{\\beta_j^S} \\sum_{t = m+1}^{T}\\left((y_t - (x_t^F)'\\beta^F)\\cfrac{\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}{\\sigma_j} - (x_t^S)'\\cfrac{\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}{\\sigma_j}\\beta_j^S\\right)^2.\n\\end{align*}\\] We now move on to the next step and take the derivative with respect to \\(\\beta^F\\), obtaining: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\beta^F} = \\cfrac{(y_t - (x_t^S)'\\beta_{s_t}^S - (x_t^F)'\\beta^F)x_t^F}{\\sigma_{s_t}^2} \\quad \\forall s_t \\in \\{1,...,N\\}.\n\\end{align*}\\] We then substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^F}{\\sigma_{s_t,{(l+1)}}^2}P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cfrac{(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)x_t^F}{\\sigma_{s_t,(l+1)}^2}P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2} = \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(x_t^F)'\\beta_{(l+1)}^Fx_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2} = \\sum_{t = m+1}^{T}(x_t^F)'\\beta_{(l+1)}^Fx_t^F\\sum_{s_t = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2} = \\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\beta_{(l+1)}^F\\sum_{s_t = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2} = \\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\sum_{s_t = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\\beta_{(l+1)}^F\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2} = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\sum_{s_t = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\\right)\\beta_{(l+1)}^F\n\\\\& \\Leftrightarrow \\beta_{(l+1)}^F = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\sum_{s_t = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\\right)^{-1}\\left(\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}(y_t - (x_t^S)'\\beta_{s_t,(l+1)}^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = s_t|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_{s_t,(l+1)}^2}\\right).\n\\end{align*}\\] As a third step, we now take the derivative with respect to \\(\\sigma_j^{-2}\\) and obtain: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\sigma_j^{-2}} = \\cfrac{\\sigma_j^2}{2} - \\cfrac{(y_t - (x_t^S)'\\beta_j^S - (x_t^F)'\\beta^F)^2}{2} \\quad \\text{if $S_t = j$ else $0$}.\n\\end{align*}\\] We now substitute this into (39) and obtain: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\sigma_j^{-2}}\\Big|_{\\alpha = \\alpha^{(l+1)}}      P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\left(\\cfrac{\\sigma_{j,(l+1)}^2}{2} - \\cfrac{(y_t - (x_t^S)'\\beta_{j,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)^2}{2} \\right)P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = 0\n\\\\& \\Leftrightarrow \\sum_{t = m+1}^{T}\\sigma_{j,(l+1)}^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}(y_t - (x_t^S)'\\beta_{j,(l+1)}^S - (x_t^F)'\\beta_{(l+1)}^F)^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sigma_{j,(l+1)}^2\\sum_{t = m+1}^{T} P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T) = \\sum_{t = m+1}^{T}(y_t - (x_t^S)'\\beta_{j,s_t}^S - (x_t^F)'\\beta_{(l+1)}^F)^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)\n\\\\& \\Leftrightarrow \\sigma_{j,(l+1)}^2 = \\cfrac{\\sum_{t = m+1}^{T}(y_t - (x_t^S)'\\beta_{j,s_t}^S - (x_t^F)'\\beta_{(l+1)}^F)^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sum_{t = m+1}^{T} P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}.\n\\end{align*}\\] We can now combine these three results into a single optimization problem, which leads us to the next \\(\\alpha\\). This is necessary because, once again, all three conditions must be satisfied simultaneously and cannot be implemented sequentially, as each of the three variables plays a role in the different conditions. We thus obtain another constrained optimization problem, but this time under two constraints: \\[\\begin{align*}\n&\\arg\\min_{\\beta_j^S} \\sum_{t = m+1}^{T}\\left((y_t - (x_t^F)'\\beta^F)\\cfrac{\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}{\\sigma_j} - (x_t^S)'\\cfrac{\\sqrt{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}{\\sigma_j}\\beta_j^S\\right)^2 \\quad s.t.\\\\\n&\\beta^F = \\left(\\sum_{t = m+1}^{T}x_t^F(x_t^F)'\\sum_{j = 1}^{N}\\cfrac{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_j^2}\\right)^{-1}\\left(\\sum_{t = m+1}^{T}\\sum_{j = 1}^{N}(y_t - (x_t^S)'\\beta_j^S)x_t^F\\cfrac{P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sigma_j^2}\\right) \\\\\n&\\sigma_j = \\sqrt{\\cfrac{\\sum_{t = m+1}^{T}(y_t - (x_t^S)'\\beta_j^S - (x_t^F)'\\beta^F)^2 P_{\\lambda_l}(S_t = j|\\mathcal{Y}_T = \\vec{y}_T)}{\\sum_{t = m+1}^{T} P_{\\lambda_l}(s_t = j|\\mathcal{Y}_T = \\vec{y}_T)}}.\n\\end{align*}\\]",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#forecasting-with-markov-switching-models",
    "href": "Markov_Switching_Models.html#forecasting-with-markov-switching-models",
    "title": "Markov-Switching-Models",
    "section": "Forecasting with Markov-Switching Models",
    "text": "Forecasting with Markov-Switching Models\nNext, we would like to turn to the topic of forecasts using Markov-Switching models. We recall that the conditional density is given by \\(f_{Y_t|S_t,\\mathcal{Y}_{t-1}; \\alpha}(y_t|j,\\vec{y}_{t-1})\\). If we now have \\(\\vec{y}_t\\) and \\(s_{t+1}\\), we could, for a simple AR(1) model, state: \\[\\begin{align*}\nY_{t+1} = c_{s_{t+1}} + \\phi_{s_{t+1}}Y_t + U_{t+1},\n\\end{align*}\\] where we have \\(E_{\\alpha}(Y_{t+1}|S_{t+1} = j, \\mathcal{Y}_t = \\vec{y}_t) = c_j + \\phi_j y_t\\). Furthermore, we can show the following for an m-step ahead forecast: \\[\\begin{align*}\n\\displaystyle\nE_{\\theta}(Y_{t+m}|\\mathcal{Y}_t = \\vec{y}_t)\n&= \\int y_{t+m}f_{Y_{t+m}|\\mathcal{Y}_t;\\theta}(y_{t+m}|\\vec{y}_t) \\,dy_{t+m}\n\\\\ &= \\int y_{t+m}\\left(\\sum_{j = 1}^{N}f_{Y_{t+m},S_{t+m}|\\mathcal{Y}_T;\\theta}(y_{t+m},j|\\vec{y}_t)\\right) \\,dy_{t+m}\n\\\\ &= \\int y_{t+m}\\left(\\sum_{j = 1}^{N}f_{Y_{t+1}|S_{t+m},\\mathcal{Y}_t;\\alpha}(y_{t+m}|j,\\vec{y}_t)P_{\\theta}(S_{t+m} = j|\\mathcal{Y}_t = \\vec{y}_t)\\right) \\,dy_{t+m}\n\\\\ &= \\sum_{j = 1}^{N}P_{\\theta}(S_{t+m} = j|\\mathcal{Y}_t = \\vec{y}_t)\n\\int y_{t+m}f_{Y_{t+m}|S_{t+m},\\mathcal{Y}_t;\\alpha}(y_{t+m}|j,\\vec{y}_t) \\,dy_{t+m}\n\\\\ &= \\sum_{j = 1}^{N}P_{\\theta}(S_{t+m} = j|\\mathcal{Y}_t = \\vec{y}_t)\nE_{\\alpha}(Y_{t+m}|S_{t+m} = j,\\mathcal{Y}_t = \\vec{y}_t).\n\\end{align*}\\] One could thus say that the forecasts for \\(y_{t+m}\\) correspond to a weighted average of the expected values given the regime, with the regime probabilities as the weights. To summarize this notation, we can say that we collect the \\(E_{\\alpha}(Y_{t+m}|S_{t+m} = j, \\mathcal{Y}_t = \\vec{y}_t)\\) in \\(\\mathbf{h_t'}\\), so that we can write \\(E_{\\theta}(Y_{t+m}|\\mathcal{Y}_t = \\vec{y}_t) = \\mathbf{h_t'} \\hat{\\zeta}_{t+m|t}\\), this derivation closely followed Hamilton (1994, page 694-695).",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#regime-forecasting-with-markov-switching-models",
    "href": "Markov_Switching_Models.html#regime-forecasting-with-markov-switching-models",
    "title": "Markov-Switching-Models",
    "section": "Regime Forecasting with Markov-Switching Models",
    "text": "Regime Forecasting with Markov-Switching Models\nThe probability that the Markov-Chain will be in a particular state in the future can be considered as \\(E_{\\theta}(\\zeta_{t+m}|\\mathcal{Y}_t = \\vec{y}_t)\\). Based on (14), this is given by: \\[\\begin{equation}\nE_{\\theta}(\\zeta_{t+m}|\\mathcal{Y}_t = \\vec{y}_t) = (\\Pi')^mE_{\\theta}(\\zeta_t|\\mathcal{Y}_t = \\vec{y}_t),\n\\end{equation}\\] or alternatively: \\[\\begin{equation}\n\\hat{\\zeta}_{t+m|t} = (\\Pi')^m \\hat{\\zeta}_{t|t}.\n\\end{equation}\\]",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#optimal-inference-of-the-regimes-and-derivation-of-the-log-likelihood-1",
    "href": "Markov_Switching_Models.html#optimal-inference-of-the-regimes-and-derivation-of-the-log-likelihood-1",
    "title": "Markov-Switching-Models",
    "section": "Optimal Inference of the Regimes and Derivation of the Log-Likelihood",
    "text": "Optimal Inference of the Regimes and Derivation of the Log-Likelihood\nThe following derivation closely follows Hamilton (1994, page 693). First of all, it is essential to keep in mind that \\((\\hat{\\zeta}_{t|t-1})_j = P_{\\theta}(S_t = j|\\mathcal{Y}_{t-1} = \\vec{y}_{t-1})\\) and \\((\\eta_t)_j = f_{Y_t|S_t, \\mathcal{Y}_{t-1};\\alpha}(y_t|j,\\vec{y}_{t-1})\\). Based on this we can see that: \\[\\begin{align*}\n\\displaystyle\n    (\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)_j &= P_{\\theta}(S_t = j|\\mathcal{Y}_{t-1} = \\vec{y}_{t-1})f_{Y_t|S_t,\\mathcal{Y}_{t-1};\\alpha}(y_t|j,\\vec{y}_{t-1})\n    \\\\&= f_{Y_t,S_t|\\mathcal{Y}_{t-1};\\theta}(y_t,j|\\vec{y}_{t-1}).\n\\end{align*}\\] If we now sum over all potential values of \\(S_t\\) we get: \\[\\begin{align*}\n       \\sum_{j = 1}^{N}f_{Y_t,S_t|\\mathcal{Y}_{t-1};\\theta}(y_t,j|\\vec{y}_{t-1}) = f_{Y_t|\\mathcal{Y}_{t-1};\\theta}(y_t|\\vec{y}_{t-1}) = \\mathbf{1'}(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t).\n\\end{align*}\\] Additionally it is therefore true that: \\[\\begin{align*}\n    \\cfrac{(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)_j}{\\mathbf{1'}(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)} = \\cfrac{f_{Y_t,S_t|\\mathcal{Y}_{t-1};\\theta}(y_t,j|\\vec{y}_{t-1})}{f_{Y_t|\\mathcal{Y}_{t-1};\\theta}(y_t|\\vec{y}_{t-1})} = P_{\\theta}(S_t = j|\\mathcal{Y}_t = \\vec{y}_{t}) = (\\hat{\\zeta}_{t|t})_j.\n\\end{align*}\\] Utilizing vectors we can write: \\[\\begin{align*}\n\\hat{\\zeta}_{t|t} = \\cfrac{(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)}{\\mathbf{1'}(\\hat{\\zeta}_{t|t-1} \\odot \\eta_t)}.\n\\end{align*}\\] To put it as simple as possible one could say that we basically just applied Bayes Rule. Next we want to get from \\((\\hat{\\zeta}_{t|t})_j = P_{\\theta}(S_t = j|\\mathcal{Y}_t = \\vec{y}_{t})\\) to \\((\\hat{\\zeta}_{t+1|t})_j = P_{\\theta}(S_{t+1} = j|\\mathcal{Y}_t = \\vec{y}_{t})\\). We know from (14) that this is possible via: \\[\\begin{align*}\n    E_{\\theta}(\\zeta_{t+1}|\\mathcal{Y}_t = \\vec{y}_t) = \\Pi'\\hat{\\zeta}_{t|t}.\n\\end{align*}\\]",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#smoothed-inference-over-the-regimes-1",
    "href": "Markov_Switching_Models.html#smoothed-inference-over-the-regimes-1",
    "title": "Markov-Switching-Models",
    "section": "Smoothed Inference over the Regimes",
    "text": "Smoothed Inference over the Regimes\nThe following derivation closely follows Hamilton (1994, page 700-702). First we note that \\(S_t\\) depends on \\(\\mathcal{Y}_{t-1}\\) through \\(S_{t-1}\\) and on future observations only through \\(S_{t+1}\\)! One could say: \\[\\begin{align*}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_T = \\vec{y}_{T}) = P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_t = \\vec{y}_{t}).\n\\end{align*}\\]\nWe can show this formally: \\[\\begin{align*}\n\\displaystyle\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n&= P_{\\theta}(S_t = j|S_{t+1} = i,Y_{t+1} = y_{t+1},\\mathcal{Y}_{t} = \\vec{y}_{t})\n\\\\ &= \\cfrac{P_{\\theta}(S_t = j,Y_{t+1} = y_{t+1}|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t})}{f_{Y_{t+1}|S_{t+1},\\mathcal{Y}_t;\\alpha}(y_{t+1}|i,\\vec{y}_{t})}\n\\\\ &= \\cfrac{f_{Y_{t+1}|S_t,S_{t+1},\\mathcal{Y}_{t};\\alpha}(y_{t+1}|j,i,\\vec{y}_{t})}{f_{Y_{t+1}|S_{t+1},\\mathcal{Y}_t;\\alpha}(y_{t+1}|i,\\vec{y}_{t})}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t})\n\\\\ &= \\cfrac{f_{Y_{t+1}|S_{t+1},\\mathcal{Y}_t;\\alpha}(y_{t+1}|i,\\vec{y}_{t})}{f_{Y_{t+1}|S_{t+1},\\mathcal{Y}_t;\\alpha}(y_{t+1}|i,\\vec{y}_{t})}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t})\n\\\\ &= P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t}).\n\\end{align*}\\] The last two steps are possible because based on (11) the distribution of \\(Y_{t+1}\\) conditional on \\(S_{t+1}\\) is independent of \\(S_{t}\\). Now we can approach the derivation for \\(t+2\\) in a similar way: \\[\\begin{align*}\n\\displaystyle\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+2} = \\vec{y}_{t+2})\n&= P_{\\theta}(S_t = j|S_{t+1} = i,Y_{t+2} = y_{t+2},\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ & = \\cfrac{P_{\\theta}(S_t = j,Y_{t+2} = y_{t+2}|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1}) }{f_{Y_{t+2}|S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|i,\\vec{y}_{t+1})}\n\\\\ &= \\cfrac{f_{Y_{t+2}|S_t,S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|j,i,\\vec{y}_{t+1})}{f_{Y_{t+2}|S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|i,\\vec{y}_{t+1})}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ &= \\cfrac{f_{Y_{t+2}|S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|i,\\vec{y}_{t+1})}{f_{Y_{t+2}|S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|i,\\vec{y}_{t+1})}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ &= P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ &= P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t}).\n\\end{align*}\\] Simplifying the fraction is possible because: \\[\\begin{align*}\n\\displaystyle\nf_{Y_{t+2}|S_t,S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2}|j,i,\\vec{y}_{t+1})  &= \\sum_{k = 1}^{N}f_{Y_{t+2},S_{t+2}|S_t, S_{t+1}, \\mathcal{Y}_{t+1};\\theta}(y_{t+2},k|j,i,\\vec{y}_{t+1})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+2}|S_{t+2},S_t, S_{t+1}, \\mathcal{Y}_{t+1};\\alpha}(y_{t+2}|k,j,i,\\vec{y}_{t+1})\n\\\\ & \\hspace{0.5cm} \\cdot P_{\\theta}(S_{t+2}=k|S_{t+1} = i, S_{t} = j,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+2}|S_{t+2}, S_{t+1}, \\mathcal{Y}_{t+1};\\alpha}(y_{t+2}|k,i,\\vec{y}_{t+1})\n\\\\ & \\hspace{0.5cm} \\cdot P_{\\theta}(S_{t+2}=k|S_{t+1} = i,\\mathcal{Y}_{t+1} = \\vec{y}_{t+1})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+2},S_{t+2}|S_{t+1},\\mathcal{Y}_{t+1};\\theta}(y_{t+2},k|i,\\vec{y}_{t+1})\n\\\\ &= f_{Y_{t+2}|S_{t+1}, \\mathcal{Y}_{t+1};\\theta}(y_{t+2}|i,\\vec{y}_{t+1}).\n\\end{align*}\\] We show now by induction that this approach is generally applicable. The earlier shown cases were the start of the induction, for the induction step we can say, we choose an arbitrary, but feasible, \\(n\\) and our induction assumption is: \\[\\begin{equation}\n    P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+n} = \\vec{y}_{t+n}) = P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_t = \\vec{y}_{t}).\n\\end{equation}\\] Then it shall hold that: \\[\\begin{equation}\n    P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+n+1} = \\vec{y}_{t+n+1}) = P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_t = \\vec{y}_{t}).\n\\end{equation}\\] To show that we write: \\[\\begin{align*}\nP_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+n+1} = \\vec{y}_{t+n+1}) &= P_{\\theta}(S_t =j|S_{t+1}=i,Y_{t+n+1} = y_{t+n+1},\\mathcal{Y}_{t+n} = \\vec{y}_{t+n})\n\\\\ &= \\cfrac{f_{S_t, Y_{t+n+1}|S_{t+1}, \\mathcal{Y}_{t+n};\\theta}(j,y_{t+n+1}|i,\\vec{y}_{t+n})}{f_{Y_{t+n+1}|S_{t+1},\\mathcal{Y}_{t+n};\\theta}(y_{t+n+1}|i,\\vec{y}_{t+n})}\n\\\\ &= \\cfrac{f_{Y_{t+n+1}|S_t,S_{t+1},\\mathcal{Y}_{t+n};\\theta}(y_{t+n+1}|j,i,\\vec{y}_{t+n})}{f_{Y_{t+n+1}|S_{t+1},\\mathcal{Y}_{t+n};\\theta}(y_{t+n+1}|i,\\vec{y}_{t+n})}\n\\\\& \\hspace{0.5cm} \\cdot P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+n} = \\vec{y}_{t+n})\n\\\\ &= P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_{t+n} = \\vec{y}_{t+n})\n\\\\ &= P_{\\theta}(S_t = j|S_{t+1} = i,\\mathcal{Y}_t = \\vec{y}_{t}).\n\\end{align*}\\] Thereby, the last step is just applying the induction assumption and simplifying the fraction is possible because: \\[\\begin{align*}\nf_{Y_{t+n+1}|S_t, S_{t+1}, \\mathcal{Y}_{t+n};\\theta}(y_{t+n+1}|j,i,\\vec{y}_{t+n}) &= \\sum_{k = 1}^{N}f_{Y_{t+n+1},S_{t+n+1}|S_t, S_{t+1}, \\mathcal{Y}_{t+n};\\theta}(y_{t+n+1},k|j,i, \\vec{y}_{t+n})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+n+1}|S_{t+n+1}, S_t, S_{t+1},\\mathcal{Y}_{t+n};\\alpha}(y_{t+n+1}|k,j,i,\\vec{y}_{t+n})\n\\\\& \\hspace{0.5cm} \\cdot P_{\\theta}(S_{t+n+1} = k|S_t = j, S_{t+1} = i, \\mathcal{Y}_{t+n} = \\vec{y}_{t+n})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+n+1}|S_{t+n+1}, S_{t+1},\\mathcal{Y}_{t+n};\\alpha}(y_{t+n+1}|k,i,\\vec{y}_{t+n})\n\\\\& \\hspace{0.5cm} \\cdot P_{\\theta}(S_{t+n+1} = k| S_{t+1} = i, \\mathcal{Y}_{t+n} = \\vec{y}_{t+n})\n\\\\ &= \\sum_{k = 1}^{N}f_{Y_{t+n+1},S_{t+n+1}|S_{t+1},\\mathcal{Y}_{t+n};\\theta}(y_{t+n+1},k|i,\\vec{y}_{t+n})\n\\\\ &= f_{Y_{t+n+1}|S_{t+1}, \\mathcal{Y}_{t+n};\\theta}(y_{t+n+1}|i,\\vec{y}_{t+n}).\n\\end{align*}\\] Once this is done it can be seen that: \\[\\begin{align*}\nP_{\\theta}(S_{t} = j|S_{t+1} = i,\\mathcal{Y}_{t+m} = \\vec{y}_{t+m}) = P_{\\theta}(S_{t} = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t}).\n\\end{align*}\\] From this follows the original claim: \\[\\begin{align*}\nP_{\\theta}(S_{t} =j|S_{t+1}=i,\\mathcal{Y}_{T} = \\vec{y}_{T}) = P_{\\theta}(S_{t} = j|S_{t+1} = i, \\mathcal{Y}_{t} = \\vec{y}_{t}).\n\\end{align*}\\] Next we can see that: \\[\\begin{align*}\n\\displaystyle\nP_{\\theta}(S_{t} =j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t})\n&= \\cfrac{P_{\\theta}(S_{t}=j,S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\\\ &= \\cfrac{P_{\\theta}(S_{t+1} = i|S_{t}=j,\\mathcal{Y}_{t} = \\vec{y}_{t})P_{\\theta}(S_{t}=j|\\mathcal{Y}_{t} = \\vec{y}_{t})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\\\ &= \\cfrac{P_{\\theta}(S_{t+1} = i|S_{t}=j)P_{\\theta}(S_{t}=j|\\mathcal{Y}_{t} = \\vec{y}_{t})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\\\ &= \\cfrac{\\pi_{j,i}P_{\\theta}(S_{t}=j|\\mathcal{Y}_{t} = \\vec{y}_t)}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}.\n\\end{align*}\\] From this it follows that: \\[\\begin{align*}\n\\displaystyle\nP_{\\theta}(S_{t} = j,S_{t+1} =i|\\mathcal{Y}_{T} = \\vec{y}_{T})\n&= P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{T} = \\vec{y}_{T})P_{\\theta}(S_{t} = j|S_{t+1} = i,\\mathcal{Y}_{T}  =\\vec{y}_{T})\n\\\\ &= P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{T} = \\vec{y}_{T})P_{\\theta}(S_{t} = j|S_{t+1} = i,\\mathcal{Y}_{t} = \\vec{y}_{t})\n\\\\ &=  P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{T} = \\vec{y}_{T})\\cfrac{\\pi_{j,i}P_{\\theta}(S_{t}=j|\\mathcal{Y}_{t} = \\vec{y}_{t})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}.\n\\end{align*}\\] Therefore, the smoothed inference over \\(S_t\\) is given by: \\[\\begin{align*}\n\\displaystyle\nP_{\\theta}(S_{t} = j|\\mathcal{Y}_{T} = \\vec{y}_{T})\n&= \\sum_{i = 1}^{N}P_{\\theta}(S_t =j,S_{t+1} = i|\\mathcal{Y}_{T} = \\vec{y}_{T})\n\\\\ &= \\sum_{i = 1}^{N}P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{T} = \\vec{y}_{T})\\cfrac{\\pi_{j,i}P_{\\theta}(S_{t}=j|\\mathcal{Y}_{t} = \\vec{y}_{t})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\\\ &= P_{\\theta}(S_t = j|\\mathcal{Y}_{t} = \\vec{y}_{t})\\sum_{i = 1}^{N}\\cfrac{\\pi_{j,i}P_{\\theta}(S_{t+1}=i|\\mathcal{Y}_{T} = \\vec{y}_{T})}{P_{\\theta}(S_{t+1} = i|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\\\ &= P_{\\theta}(S_t = j|\\mathcal{Y}_{t} = \\vec{y}_{t})(\\pi_{j,1} ... \\pi_{j,N})\\begin{pmatrix}\n\\cfrac{P_{\\theta}(S_{t+1} = 1|\\mathcal{Y}_{T} = \\vec{y}_{T})}{P_{\\theta}(S_{t+1} = 1|\\mathcal{Y}_{t} = \\vec{y}_{t})}\\\\\n...\\\\\n\\cfrac{P_{\\theta}(S_{t+1} = N|\\mathcal{Y}_{T} = \\vec{y}_{T})}{P_{\\theta}(S_{t+1} = N|\\mathcal{Y}_{t} = \\vec{y}_{t})}\n\\end{pmatrix}\n\\\\ &= P_{\\theta}(S_{t} =j|\\mathcal{Y}_{t} = \\vec{y}_{t})\\Pi_{j,}(\\hat{\\zeta}_{t+1|T} (\\div) \\hat{\\zeta}_{t+1|t}).\n\\end{align*}\\] Where \\(\\Pi_{j,}\\) is the jth row of \\(\\Pi\\). For the vector of probabilities one can therefore write: \\[\\begin{align*}\n    \\hat{\\zeta}_{t|T} = \\hat{\\zeta}_{t|t} \\odot \\Pi(\\hat{\\zeta}_{t+1|T} (\\div) \\hat{\\zeta}_{t+1|t}).\n\\end{align*}\\] This is the earlier presented formula.",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "Markov_Switching_Models.html#em-algorithm-for-autoregressive-processes-with-finite-lag-order",
    "href": "Markov_Switching_Models.html#em-algorithm-for-autoregressive-processes-with-finite-lag-order",
    "title": "Markov-Switching-Models",
    "section": "EM Algorithm for Autoregressive Processes with finite lag order",
    "text": "EM Algorithm for Autoregressive Processes with finite lag order\nThe here presented proofs for the equations (38), (39) and (40) closely follow Hamilton (1990, page 63-67). We begin with (38), then go on to (39) and finish with the proof for (40). The first, essential step for all three proofs, is to establish that the following holds: \\[\\begin{equation}\n\\begin{aligned}\nf_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m) = & f_{Y_T|Z_T;\\alpha}(y_T|z_T) \\cdot P_{\\Pi}(S_T = s_T|S_{T-1} = s_{T-1}) \\\\\n& \\cdot f_{Y_{T-1}|Z_{T-1};\\alpha}(y_{T-1}|z_{T-1}) \\cdot P_{\\Pi}(S_{T-1} = s_{T-1}|S_{T-2} = s_{T-2}) \\\\\n& \\cdot... \\\\\n& \\cdot f_{Y_{m+1}|Z_{m+1};\\alpha}(y_{m+1}|z_{m+1}) \\cdot P_{\\Pi}(S_{m+1} = s_{m+1}|S_m = s_m) \\\\\n& \\cdot \\rho_{s_m,...,s_1}.\n\\end{aligned}\n\\end{equation}\\] This can be derived in the following way: \\[\\begin{align*}\n\\displaystyle\n&f_{Y_T|Z_T;\\alpha}(y_T|z_T) \\cdot P_{\\Pi}(S_T = s_T|S_{T-1} = s_{T-1})\n\\\\& \\cdot f_{Y_{T-1}|Z_{T-1};\\alpha}(y_{T-1}|z_{T-1}) \\cdot P_{\\Pi}(S_{T-1} = s_{T-1}|S_{T-2} = s_{T-2})\\\\\n& \\cdot...\\\\\n& \\cdot f_{Y_{m+1}|Z_{m+1};\\alpha}(y_{m+1}|z_{m+1}) \\cdot P_{\\Pi}(S_{m+1} = s_{m+1}|S_m = s_m)\\\\\n& \\cdot \\rho_{s_m,...,s_1}\n\\\\ &= f_{Y_T|S_T,...,S_{T-m},Y_{T-1},...,Y_{T-m};\\alpha}(y_T|s_T,...,s_{T-m},y_{T-1},...,y_{T-m})\nP_{\\Pi}(S_T = s_T|S_{T-1} = s_{T-1})\\\\\n& \\hspace{0.5cm} \\cdot f_{Y_{T-1}|S_{T-1},...,S_{T-1-m},Y_{T-1-1},...,Y_{T-1-m};\\alpha}(y_{T-1}|s_{T-1},...,s_{T-1-m},y_{T-1-1},...,y_{T-1-m})\n\\\\& \\hspace{0.5cm} \\cdot P_{\\Pi}(S_{T-1} = s_{T-1}|S_{T-2} = s_{T-2})\n\\\\& \\hspace{0.5cm} \\cdot \\dots \\\\\n&  \\hspace{0.5cm}\\cdot f_{Y_{m+2}|S_{m+2},...,S_2,Y_{m+1},...,Y_2;\\alpha}(y_{m+2}|s_{m+2},...,s_2,y_{m+1},...,y_2)\nP_{\\Pi}(S_{m+2} = s_{m+2}|S_{m+1} = s_{m+1})\\\\\n& \\hspace{0.5cm}\\cdot f_{Y_{m+1}|S_{m+1},...,S_1,Y_{m},...,Y_1;\\alpha}(y_{m+1}|s_{m+1},...,s_1,y_{m},...,y_1)\nP_{\\Pi}(S_{m+1} = s_{m+1}|S_{m} = s_{m})\\\\\n& \\hspace{0.5cm}\\cdot P_{\\lambda}(S_m = s_m,...,S_1 = s_1|Y_m = y_m,...,Y_1 = y_1).\n\\end{align*}\\] And due to the Markov property and (12) it holds that: \\[\\begin{align*}\n\\displaystyle\n& f_{Y_{m+1}|S_{m+1},...,S_1,Y_{m},...,Y_1;\\alpha}(y_{m+1}|s_{m+1},...,s_1,y_{m},...,y_1)\nP_{\\Pi}(S_{m+1} = s_{m+1}|S_{m} = s_{m})\n\\\\ &= f_{Y_{m+1}|S_{m+1},...,S_1,Y_{m},...,Y_1;\\alpha}(y_{m+1}|s_{m+1},...,s_1,y_{m},...,y_1)\nP_{\\Pi}(S_{m+1} = s_{m+1}|S_{m} = s_{m},...,S_1 = s_1)\n\\\\ &= f_{Y_{m+1}|S_{m+1},...,S_1,Y_{m},...,Y_1;\\alpha}(y_{m+1}|s_{m+1},...,s_1,y_{m},...,y_1)\n\\\\& \\hspace{0.5cm} \\cdot \\ P_{\\Pi}(S_{m+1} = s_{m+1}|S_{m} = s_{m},...,S_1 = s_1,Y_m = y_m,...,Y_1 = y_1)\n\\\\ &= f_{Y_{m+1},S_{m+1}|S_m,...,S_1,Y_m,...,Y_1;\\theta}(y_{m+1},s_{m+1}|s_m,...,s_1,y_m,...,y_1).\n\\end{align*}\\] Logically it also holds that: \\[\\begin{align*}\n\\displaystyle\n& f_{Y_{m+1},S_{m+1}|S_m,...,S_1,Y_m,...,Y_1;\\theta}(y_{m+1},s_{m+1}|s_m,...,s_1,y_m,...,y_1)\n\\cdot P_{\\lambda}(S_m = s_m,...,S_1 = s_1|Y_m = y_m,...,Y_1 = y_1)\n\\\\& = f_{Y_{m+1},S_{m+1},S_{m},...,S_1|Y_m,...,Y_1;\\theta}(y_{m+1},s_{m+1},...,s_1|y_m,...,y_1).\n\\end{align*}\\] We assumed in our model formulation in 4.1 that there is a maximal autoregressive lag order \\(m\\) such that \\(Y_t\\), depends only on \\(m\\) lags of \\(Y_t\\). Then it holds that: \\[\\begin{align*}\n&f_{Y_{m+2}|S_{m+2},...,S_2,Y_{m+1},...,Y_2;\\alpha}(y_{m+2}|s_{m+2},...,s_2,y_{m+1},...,y_2)\nP_{\\Pi}(S_{m+2} = s_{m+2}|S_{m+1} = s_{m+1})\n\\\\ &= f_{Y_{m+2}|S_{m+2},...,S_2,S_1,Y_{m+1},...,Y_2,Y_1;\\alpha}(y_{m+2}|s_{m+2},...,s_2,s_1,y_{m+1},...,y_2,y_1)\nP_{\\Pi}(S_{m+2} = s_{m+2}|S_{m+1} = s_{m+1})\n\\\\ &= f_{Y_{m+2}|S_{m+2},...,S_2,S_1,Y_{m+1},...,Y_2,Y_1;\\alpha}(y_{m+2}|s_{m+2},...,s_2,s_1,y_{m+1},...,y_2,y_1)\n\\\\&  \\hspace{0.5cm} \\cdot P_{\\Pi}(S_{m+2} = s_{m+2}|S_{m+1} = s_{m+1},S_m = s_m,...,S_1 = s_1,Y_{m+1} = y_{m+1},...,Y_1 = y_1)\n\\\\ &= f_{Y_{m+2},S_{m+2}|S_{m+1},S_m,...,S_1,Y_{m+1},Y_m,...,Y_1;\\theta}(y_{m+2},s_{m+2}|s_{m+1},s_m,...,s_1,y_{m+1},y_m,...,y_1).\n\\end{align*}\\] And thus we can write: \\[\\begin{align*}\n\\displaystyle\n&f_{Y_{m+2},S_{m+2}|S_{m+1},S_m,...,S_1,Y_{m+1},Y_m,...,Y_1;\\theta}(y_{m+2},s_{m+2}|s_{m+1},s_m,...,s_1, y_{m+1},y_m,...,y_1)\n\\\\ &\\cdot f_{Y_{m+1},S_{m+1},S_{m},...,S_1|Y_m,...Y_1;\\theta}(y_{m+1},s_{m+1},s_{m},...,s_1|y_m,...,y_1)\n\\\\ &= f_{Y_{m+2},S_{m+2}|S_{m+1},Y_{m+1},S_m,...,S_1,Y_m,...,Y_1;\\theta}(y_{m+2},s_{m+2}|s_{m+1},y_{m+1},s_m,...,s_1,y_m,...,y_1)\n\\\\& \\hspace{0.5cm} \\cdot f_{Y_{m+1},S_{m+1},S_{m},...,S_1|Y_m,...Y_1;\\theta}(y_{m+1},s_{m+1},s_{m},...,s_1|y_m,...,y_1)\n\\\\ &= f_{Y_{m+2},S_{m+2},Y_{m+1},S_{m+1},S_m,...S_1|Y_{m},...Y_1;\\theta}(y_{m+2},s_{m+2},y_{m+1},s_{m+1}, s_m,...,s_1|y_{m},...,y_1).\n\\end{align*}\\] We can follow this logic until \\(T\\) and end up with: \\[\\begin{align*}\n\\displaystyle\n& f_{Y_T|S_T,...,S_{T-m},Y_{T-1},...,Y_{T-m};\\alpha}(y_T|s_T,...,s_{T-m},y_{T-1},...,y_{T-m})P_{\\Pi}(S_T = s_T|S_{T-1} = s_{T-1})\\\\\n&\\cdot f_{Y_{T-1}|S_{T-1},...,S_{T-1-m},Y_{T-1-1},...,Y_{T-1-m};\\alpha}(y_{T-1}|s_{T-1},...,s_{T-1-m}, y_{T-1-1},...,y_{T-1-m})\n\\\\& \\cdot P_{\\Pi}(S_{T-1} = s_{T-1}|S_{T-2} = s_{T-2})\\\\\n& \\cdot \\dots\\\\\n&\\cdot f_{Y_{m+2}|S_{m+2},...,S_2,Y_{m+1},...,Y_2;\\alpha}(y_{m+2}|s_{m+2},...,s_2, y_{m+1},...,y_2)P_{\\Pi}(S_{m+2} = s_{m+2}|S_{m+1} = s_{m+1})\\\\\n&\\cdot f_{Y_{m+1}|S_{m+1},...,S_2,Y_{m},...,Y_1;\\alpha}(y_{m+1}|s_{m+1},...,s_2,y_{m},...,y_1) P_{\\Pi}(S_{m+1} = s_{m+1}|S_m = s_{m})\\\\\n&\\cdot P_{\\lambda}(S_m = s_m,...,S_1 = s_1|Y_m = y_m,...,Y_1 = y_1)\n\\\\ &= f_{Y_T,S_T,Y_{T-1},S_{T-1},...,Y_{m+1},S_{m+1},S_m,...,S_1|Y_m,...,Y_1;\\lambda}(y_T,s_T,y_{T-1}, s_{T-1},...,y_{m+1},s_{m+1}, s_m,..., s_1| y_m,..., y_1)\n\\\\ &= f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m).\n\\end{align*}\\]\nNow that this first step has been established, we can now focus on the derivation of the first equation, thereby we are closely following Hamilton (1990, page 63-65). We start with (55), it holds that: \\[\\begin{equation}\n\\begin{aligned}\n\\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))\n&= \\ln(f_{Y_T|Z_T;\\alpha}(y_T|z_T))\n\\\\& \\hspace{0.5cm} + \\ln(P_{\\Pi}(S_T = s_T|S_{T-1} = s_{T-1}))\\\\\n& \\hspace{0.5cm}+ \\ln(f_{Y_{T-1}|Z_{T-1};\\alpha}(y_{T-1}|z_{T-1}))\n\\\\& \\hspace{0.5cm} + \\ln(P_{\\Pi}(S_{T_1} = s_{T-1}|S_{T-2} = s_{T-2}))\\\\\n&\\hspace{0.5cm} + \\dots \\\\\n&\\hspace{0.5cm} + \\ln(f_{Y_{m+1}|Z_{m+1};\\alpha}(y_{m+1}|z_{m+1}))\n\\\\&\\hspace{0.5cm} + \\ln(P_{\\Pi}(S_{m+1} = s_{m+1}|S_m = s_m))\\\\\n&\\hspace{0.5cm} + \\ln(\\rho_{s_m,\\dots,s_1}).\n\\end{aligned}\n\\end{equation}\\] We remember that if we have \\(L(x,y)\\) and \\(\\ln(L(x,y)) = l(x,y)\\), then it is true that: \\[\\begin{align*}\n\\cfrac{\\partial l(x,y)}{\\partial x} = \\cfrac{1}{L(x,y)}\\cfrac{\\partial L(x,y)}{\\partial x},\n\\end{align*}\\] and thus \\[\\begin{align*}\n\\cfrac{\\partial L(x,y)}{\\partial x} = \\cfrac{\\partial l(x,y)}{\\partial x}L(x,y).\n\\end{align*}\\] We apply this now: \\[\\begin{align*}\n\\displaystyle\n&f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m) \\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\pi_{i,j}} \\\\ &= \\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{\\partial \\pi_{i,j}},\n\\end{align*}\\] where: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\pi_{i,j}} = \\sum_{t = m+1}^{T}\\cfrac{\\partial \\ln(P_{\\Pi}(S_t = s_t|S_{t-1} = s_{t-1}))}{\\partial \\pi_{i,j}}.\n\\end{align*}\\] One should note that: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(P_{\\Pi}(S_t = s_t|S_{t-1} = s_{t-1}))}{\\partial \\pi_{i,j}} =\n\\begin{cases}\n    \\cfrac{1}{\\pi_{i,j}}, & \\text{if $S_t =j \\quad \\text{and} \\quad S_{t-1} = i$} \\\\\n    0, & \\text{otherwise}\n\\end{cases}.\n\\end{align*}\\] In the following, we will use the Kronecker delta as notation in the following way: \\[\\begin{align*}\n\\delta_{[A]} =\n\\begin{cases}\n    1, &\\text{if A is true}\\\\\n    0, &\\text{otherwise}\n\\end{cases},\n\\end{align*}\\] thus: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{\\partial \\pi_{i,j}} &= f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\\sum_{t = m+1}^{T}\\cfrac{\\partial \\ln(P_{\\Pi}(S_t = s_t|S_{t-1} = s_{t-1}))}{\\partial \\pi_{i,j}}\n\\\\ &= f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\\cfrac{1}{\\pi_{i,j}}\\sum_{t = m+1}^{T}\\delta_{[S_t =j,S_{t-1}= i]}.\n\\end{align*}\\] We remember that the following holds: \\[\\begin{align*}\n\\displaystyle\n    Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1}) = \\sum_{\\vec{s}_{T}} \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m).\n\\end{align*}\\] Therefore, we can say: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1})}{\\partial \\pi_{i,j}^{(l+1)}} &= \\sum_{\\vec{s}_{T}}\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\pi_{i,j}^{(l+1)}}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_{T}}\\cfrac{1}{\\pi_{i,j}^{(l+1)}}\\sum_{t = m+1}^{T}\\delta_{[S_t = j, S_{t-1} = i]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m).\n\\end{align*}\\] It is now essential to notice that: \\[\\begin{align*}\n\\displaystyle\n\\sum_{\\vec{s}_{T}}\\delta_{[S_t = j,S_{t-1} = i]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n&= f_{\\mathcal{Y}_{T:(m+1)},S_t, S_{t-1}|\\mathcal{Y}_m;\\lambda_l}(\\vec{y}_{T:(m+1)},j,i)\n\\\\ &= P_{\\lambda_l}(S_t = j, S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})\n\\\\& \\hspace{0.5cm} \\cdot f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m),\n\\end{align*}\\] and that therefore: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1})}{\\partial \\pi_{i,j}^{(l+1)}}\n&= \\sum_{\\vec{s}_{T}}\\cfrac{1}{\\pi_{i,j}^{(l+1)}}\\sum_{t = m+1}^{T}\\delta_{[S_t = j, S_{t-1} = i]} f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &=\\cfrac{1}{\\pi_{i,j}^{(l+1)}}\\sum_{t = m+1}^{T}\\sum_{\\vec{s}_{T}}\\delta_{[S_t = j, S_{t-1} = i]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_l}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\cfrac{1}{\\pi_{i,j}^{(l+1)}}\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j,S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m).\n\\end{align*}\\] Under the constraint \\(\\sum_{j = 1}^{N}\\pi_{i,j} = 1\\) we can now form the Lagrangian: \\[\\begin{align*}\n\\displaystyle\nQ_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1}) - \\mu_i(\\sum_{j = 1}^{N}\\pi_{i,j} - 1).\n\\end{align*}\\] This leads to the following first-order conditons: \\[\\begin{align*}\n\\cfrac{\\partial Q_{\\lambda_{l},\\vec{y}_{T}}(\\lambda_{l+1})}{\\partial \\pi_{i,j}^{(l+1)}} = \\mu_i, \\quad \\text{for} \\quad j = 1,...,N.\n\\end{align*}\\] We insert our result from above: \\[\\begin{align*}\n\\displaystyle\n& \\cfrac{1}{\\pi_{i,j}^{(l+1)}}\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j, S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) = \\mu_i\n\\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t =j,S_{t-1}=i|\\mathcal{Y}_T = \\vec{y}_{T}) = \\cfrac{\\pi_{i,j}^{(l+1)}\\mu_i}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}.\n\\end{align*}\\] We now sum over \\(1,...,N\\), which leads to: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{j = 1}^{N}\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t = j,S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T}) = \\sum_{j = 1}^{N}\\cfrac{\\pi_{i,j}^{(l+1)}\\mu_i}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}\n\\\\ &\\Leftrightarrow \\sum_{t = m+1}^{T}P_{\\lambda_l}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T}) = \\cfrac{\\mu_i}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)}.\n\\end{align*}\\] If we now insert this in the result from above we get: \\[\\begin{align*}\n&\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t =j,S_{t-1}=i|\\mathcal{Y}_T = \\vec{y}_{T}) = \\cfrac{\\pi_{i,j}^{(l+1)}\\mu_i}{f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)} = \\pi_{i,j}^{(l+1)}\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_{t-1} = i|\\mathcal{Y}_T = \\vec{y}_{T})\n\\\\ &\\Leftrightarrow \\pi_{i,j}^{(l+1)} = \\cfrac{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_t =j,S_{t-1}=i|\\mathcal{Y}_T = \\vec{y}_{T})}{\\sum_{t = m+1}^{T}P_{\\lambda_l}(S_{t-1} = i|\\mathcal{Y}_T  =\\vec{y}_{T})},\n\\end{align*}\\] this concludes the derivation of (38).\nWith that, we get to the second equation. In the following we closely follow Hamilton (1990, page 65-66). Again, we start with (55), but this time we take the derivative in \\(\\alpha\\): \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)}{\\partial \\alpha} = f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\\sum_{t = m+1}^{T}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha}(y_t|z_t))}{\\partial \\alpha}.\n\\end{align*}\\] It is important to note here that \\(f_{Y_t|Z_t;\\alpha}(y_t|z_t)\\) depends on \\(S_t\\) through \\(Z_t\\), because \\ \\(Z_t = (S_t,S_{t-1},...,S_{t-m},Y_{t-1},Y_{t-2},...,Y_{t-m})\\), but at most for the dates \\(t,...,t-m\\), thus: \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1})}{\\partial \\alpha_{l+1}} &= \\cfrac{\\partial}{\\partial \\alpha_{l+1}}\\sum_{\\vec{s}_{T}}\\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_{T}}\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\alpha_{l+1}}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ & \\stackrel{\\text{(56)}}{=}\\sum_{\\vec{s}_{T}}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\\sum_{t = m+1}^{T}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha_{l+1}}(y_t|z_t))}{\\partial \\alpha_{l+1}}\n\\\\ &= \\sum_{t = m + 1}^{T}\\sum_{\\vec{s}_T}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha_{l+1}}(y_t|z_t))}{\\partial \\alpha_{l+1}}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha_{l+1}}(y_t|z_t))}{\\partial \\alpha_{l+1}}\n\\\\& \\hspace{0.5cm}\\cdot \\left(\\sum_{s_{T} = 1}^{N}\\cdots\\sum_{s_{t+1} = 1}^{N}\\sum_{s_{t-m-1} = 1}^{N}\\cdots\\sum_{s_{1} = 1}^{N}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\\right)\n\\\\ &= \\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N}\\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha_{l+1}}(y_t|z_t))}{\\partial \\alpha_{l+1}}\n\\\\ & \\hspace{0.5cm} \\cdot P_{\\lambda_l}(S_t = s_t,...,S_{t-m} = s_{t-m}|Y_T = y_T,...,Y_1 = y_1)\n\\\\& \\hspace{0.5cm} \\cdot f_{Y_T,...,Y_{m+1}|Y_m,...,Y_1;\\lambda_l}(y_T,...,y_{m+1}|y_m,...,y_1).\n\\end{align*}\\] These steps are possible because \\(f_{Y_t|Z_t;\\alpha}(y_t|z_t)\\) at most only depends on \\(S_t,...,S_{t-m}\\). This leads us to the following first order condition: \\[\\begin{align*}\n\\displaystyle\n&f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)\\sum_{t = m+1}^{T}\\sum_{s_t = 1}^{N}\\cdots\\sum_{s_{t-m} = 1}^{N} \\cfrac{\\partial \\ln(f_{Y_t|Z_t;\\alpha_{l+1}}(y_t|z_t))}{\\partial \\alpha_{l+1}}\n\\\\& \\cdot P_{\\lambda_l}(S_t = s_t,S_{t-1} = s_{t-1},...,S_{t-m} = s_{t-m}|\\mathcal{Y}_T = \\vec{y}_{T}) = 0,\n\\end{align*}\\] which is equivalent to (39).\nNow we can turn to equation number three, here we closely follow the derivations presented by Hamilton (1990, page 66-67). We start with (56) and take the derivative in \\(\\rho_{i_m,...,i_1}\\): \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\rho_{i_m,...,i_1}} = \\cfrac{1}{\\rho_{i_m,...,i_1}}\\cdot\\delta_{[S_m = i_m,...,S_1 = i_1]},\n\\end{align*}\\] because of this, it holds that:\\ \\[\\begin{align*}\n\\displaystyle\n\\cfrac{\\partial Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1})}{\\partial\\rho_{i_m,...,i_1}^{(l+1)}}\n&= \\sum_{\\vec{s}_T}\\cfrac{\\partial \\ln(f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l+1}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m))}{\\partial \\rho_{i_m,...,i_1}^{(l+1)}}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m)\n\\\\ &= \\sum_{\\vec{s}_{T}}\\cfrac{1}{\\rho_{i_m,...,i_1}^{(l+1)}}\\delta_{[S_m = i_m,...,S_1 = i_1]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m).\n\\end{align*}\\] We want to optimize \\(Q_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1})\\) under the constraint \\(\\sum_{j = 1}^{N^m}(\\rho_{l+1})_j = 1\\), i.e that the sum of all elements of \\(\\rho_{l+1}\\) shall be 1. Thus we construct the Lagrangian: \\[\\begin{align*}\n\\displaystyle\nQ_{\\lambda_l,\\vec{y}_{T}}(\\lambda_{l+1}) - \\mu(\\sum_{j = 1}^{N^m}(\\rho_{l+1})_j-1)).\n\\end{align*}\\] Which leads to the first order condition: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{\\vec{s}_{T}} \\cfrac{1}{\\rho_{i_m,...,i_1}^{(l+1)}}\\delta_{[S_m = i_m,...,S_1 = i_1]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m) = \\mu\n\\\\ &\\Leftrightarrow \\sum_{\\vec{s}_T}\\delta_{[S_m = i_m,...,S_1 = i_1]}f_{\\mathcal{Y}_{T:(m+1)},\\mathcal{S}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)},\\vec{s}_T|\\vec{y}_m) = \\rho_{i_m,...,i_1}^{(l+1)}\\mu\n\\\\ &\\Leftrightarrow f_{S_m,...,S_1,Y_T,...,Y_{m+1}|Y_m,...,Y_1;\\lambda_l}(i_m,...,i_1,y_T,...,y_{m+1}|y_m,...,y_1) = \\rho_{i_m,...,i_1}^{(l+1)}\\mu\n\\\\ &\\Leftrightarrow P_{\\lambda_l}(S_m = i_m,...,S_1 = i_1|\\mathcal{Y}_T  =\\vec{y}_{T})f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) = \\mu \\rho_{i_m,...,i_1}^{(l+1)}.\n\\end{align*}\\] If we now sum over all potential values of \\((i_1,...i_m)\\) we end up with: \\[\\begin{align*}\n\\displaystyle\n&\\sum_{i_m = 1}^{N}\\cdots\\sum_{i_1 = 1}^{N}P_{\\lambda_l}(S_m = i_m,...,S_1 = i_1|\\mathcal{Y}_T = \\vec{y}_{T})f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)\n= \\sum_{i_m = 1}^{N}\\cdots\\sum_{i_1 = 1}^{N}\\mu \\rho_{i_m,...,i_1}^{(l+1)}\n\\\\ &\\Leftrightarrow f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) = \\mu.\n\\end{align*}\\] We insert this for \\(\\mu\\) and get: \\[\\begin{align*}\n\\displaystyle\n&P_{\\lambda_l}(S_m = i_m,...,S_1 = i_1|\\mathcal{Y}_T = \\vec{y}_{T})f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m) = f_{\\mathcal{Y}_{T:(m+1)}|\\mathcal{Y}_m;\\lambda_{l}}(\\vec{y}_{T:(m+1)}|\\vec{y}_m)\\rho_{i_m,...,i_1}^{(l+1)}\n\\\\ &\\Leftrightarrow P_{\\lambda_l}(S_m = i_m,...,S_1 = i_1|\\mathcal{Y}_T = \\vec{y}_{T}) = \\rho_{i_m,...,i_1}^{(l+1)}.\n\\end{align*}\\] This concludes the derivation of the EM algorithm for models with an underlying Markov-Chain and a dependence on a maximum lag order.",
    "crumbs": [
      "Start",
      "Blog Posts",
      "Markov-Switching Models"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Common Metrics",
    "section": "",
    "text": "Welcome to Common Metrics – a platform dedicated to sharing my current projects, ideas, and tools in a transparent and accessible way.\nMy name is Julian Müller. Through Common Metrics, I aim to document and share my work across various areas of applied statistics and economics. This includes:\n\nA transparent overview of my portfolio and the trading strategies it implements.\nBlog posts on statistical topics such as Markov Switching Models or the development and documentation of my own R package, MSARM, for estimating such models.\nReplication attempts of interesting academic papers, where I assess the robustness and reproducibility of published results.\n\nNo matter what you background is you’re welcome to give feedback regarding the blog posts or the website in general. You can find more about me in the “About Me” section."
  },
  {
    "objectID": "AboutMe.html",
    "href": "AboutMe.html",
    "title": "About Me",
    "section": "",
    "text": "Hello, my name is Julian Müller, I am 20 years old. I was born on the 21.08.2004 in California, but lived since my third birthday in Germany. I love to do sports, if possible I try to train four to five times a week. Furthermore I enjoy reading classics like Dostojewski or Homer. I studied economics at the University of Mannheim with a focus on econometrics and statistics. My elective courses included Analysis B, Analysis C, Applied Multivariate Statistics, Markov Chains, Resampling Methods, Time Series and Forecasting, Statistical Learning Methods.\nFurthermore I wrote a Seminar Paper in Applied Econometrics about Predictions with Many Regressors and Big Data. The Seminar Paper compares various prediction models within a big data context. The challenge of having too much data to achieve good predictions is a relatively modern problem, and several approaches have been developed to address it. The Paper compared some of these approaches, including shrinkage estimators, which received particular attention and a principal components based OLS Regression.\nMy Bachelor Thesis “From Theory to Application: Developing MSARM, an R Package for Markov-Switching Autoregressive Models” addresses two main objectives. First, it presents a systematic overview of the theory behind Markov-Switching models, focusing on applying the Expectation-Maximization (EM) algorithm to a broad class of Markov-Switching Autoregressive (AR) processes. Second, the thesis introduces MSARM, a new R package for estimating such models. Results from approximately 300 simulations show that MSARM’s estimation algorithm is more robust than MSwM’s, especially in more generalized settings where MSwM often fails. MSARM can be installed with the command: devtools::install github(”jmuelleo/MSARM”).\nThe University of Mannheim is in the QS Ranking 2024 rank 2 in Economics & Econometrics and could even say:\n“In this category, the University of Mannheim was evaluated in seven different areas. It was particularly successful in the area Accounting & Finance, where it ranked first in Germany. In Business & Management Studies and Economics & Econometrics it ranked second. Overall, Mannheim is hence the best-ranked German university in business and economics.”\nSee: https://www.uni-mannheim.de/en/newsroom/presse/pressemitteilungen/2024/april/qs-ranking-1/\nYou can reach me via common.metrics.contact@gmail.com\nMy CV can be downloaded via the following link:\n 📄 Download CV \nYou can find my Bachelor Thesis “From Theory to Application: Developing MSARM, an R Package for Markov-Switching Autoregressive Models” here:\n 📄 Download Bachelor Thesis  \nYou can find my Seminar Paper “Predictions with Many Regressors and Big Data” here:\n 📄 Download Seminar Paper"
  },
  {
    "objectID": "MacroShift_Theory.html",
    "href": "MacroShift_Theory.html",
    "title": "Anticipating Recessions. Allocating with Precision",
    "section": "",
    "text": "The idea behind MacroShift is relatively easy. We know that we can predict recession probabilities utilizing Markov-Switching Models, their theory is described in the blogpost “Markov-Switching Models”, the question I now want to answer is whether these predicted recession probabilities allow us to make better investment decisions. Therefore, we will estimate a Markov-Switching Model, with two underlying Regimes (recession, not-recession), then we will utilize the EM-Algorithm, Hamilton Filter and Kim-Filter to estimate smoothed regime probabilities for the past, based on several different variables (GDP, interest rate,…) from there we can predict the recession probability of the next time period (generally speaking quarter, as most macroeconomic data is quarterly data) and based on the recession probability predicted for each country we give different stocks and bonds in our portfolio different weights.\nObviously this investment strategy can be paired with other strategies, that decide which financial products to buy for a specific country, but we will start by just buying index-funds that refelct the overall economy of each country, like the S&P 500 for the US or the MDax for Germany. Then each country will be given a weight, that is inverse to their recession probability.\nTo be a bit more precise if we have \\(N\\) countries, then the country weight of country i will be calculated as: \\[\n\\begin{align}\nw_i = \\frac{1-P(R_i)}{\\sum_{k=1}^{N}(1-P(R_k))}\n\\end{align}\n\\] Where \\(P(R_k)\\) is the recession probability of country k for the next time period, and thus \\((1-P(R_k))\\) is the predicted probability that there will be no recession in country k during the next time period.As one can easiliy observe, \\(w_i\\) decreases in \\(P(R_i)\\), i.e. the country weight decreases in its recession probability.",
    "crumbs": [
      "Start",
      "MacroShift",
      "MacroShift - Underlying Theory"
    ]
  }
]